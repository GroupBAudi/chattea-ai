{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d62ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicho\\Documents\\GitHub_Repository\\Python\\chattea-ai\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHATTEA INTENT CLASSIFIER - MLP + SENTENCE TRANSFORMERS\n",
      "================================================================================\n",
      "PyTorch Version: 2.9.1+cu130\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Chattea Intent Classifier - MLP + Sentence Transformers\n",
    "# Complete Working Pipeline in Notebook Format\n",
    "# Ready to run cell by cell!\n",
    "\n",
    "\"\"\"\n",
    "JUPYTER NOTEBOOK STRUCTURE:\n",
    "Run each cell in order (Shift+Enter)\n",
    "\n",
    "Required Files:\n",
    "- chattea_dataset.csv (text, intent columns)\n",
    "- responses.json (your bilingual responses)\n",
    "\n",
    "Installation:\n",
    "!pip install torch sentence-transformers scikit-learn pandas difflib\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from difflib import get_close_matches\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CHATTEA INTENT CLASSIFIER - MLP + SENTENCE TRANSFORMERS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1978fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Using device: cuda\n",
      "üéÆ GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "üíæ GPU Memory: 8.59 GB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: DEVICE CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - training will use CPU (slower)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7b133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìÇ LOADING DATA\n",
      "================================================================================\n",
      "‚úì Loaded dataset: 657 samples\n",
      "‚úì Columns: ['text', 'intent']\n",
      "‚úì Unique intents: 33\n",
      "\n",
      "üìä Sample data:\n",
      "           text    intent\n",
      "0         hello  greeting\n",
      "1            hi  greeting\n",
      "2     hey there  greeting\n",
      "3  good morning  greeting\n",
      "4  good evening  greeting\n",
      "5      hi there  greeting\n",
      "6           hey  greeting\n",
      "7     greetings  greeting\n",
      "8     what's up  greeting\n",
      "9     hello bot  greeting\n",
      "\n",
      "üìà Intent distribution:\n",
      "intent\n",
      "greeting            20\n",
      "gratitude           20\n",
      "help                20\n",
      "definition          20\n",
      "cancel              20\n",
      "instance_manage     20\n",
      "instance_create     20\n",
      "instance_connect    20\n",
      "instance_status     20\n",
      "message_status      20\n",
      "message_send        20\n",
      "message_blast       20\n",
      "message_schedule    20\n",
      "contacts            20\n",
      "chat_view           20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Loaded responses for 32 intents\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìÇ LOADING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load training dataset\n",
    "df = pd.read_csv(\"chattea_dataset.csv\")\n",
    "print(f\"‚úì Loaded dataset: {len(df)} samples\")\n",
    "print(f\"‚úì Columns: {list(df.columns)}\")\n",
    "print(f\"‚úì Unique intents: {df['intent'].nunique()}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìä Sample data:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Intent distribution\n",
    "print(\"\\nüìà Intent distribution:\")\n",
    "intent_counts = df['intent'].value_counts()\n",
    "print(intent_counts.head(15))\n",
    "\n",
    "# Load responses\n",
    "with open(\"responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    RESPONSES = json.load(f)\n",
    "print(f\"\\n‚úì Loaded responses for {len(RESPONSES)} intents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76954e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìö BUILDING VOCABULARY FOR FUZZY MATCHING\n",
      "================================================================================\n",
      "‚úì Vocabulary size: 451 unique words\n",
      "‚úì Sample words: ['simply', 'messages', 'gallery', 'lot', 'customers', 's', 'active', 'files', 'upload', 'catch', 'morning', 'short', 'online', 'preferences', 'afternoon', 'records', 'homepage', 'don', 'where', 'this']\n",
      "\n",
      "üß™ Testing Fuzzy Correction:\n",
      "   'blst mesage' ‚Üí 'blast message'\n",
      "   'chek number' ‚Üí 'check number'\n",
      "   'craete instance' ‚Üí 'create instance'\n",
      "   'shedule mesage' ‚Üí 'schedule message'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: BUILD VOCABULARY FOR FUZZY MATCHING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö BUILDING VOCABULARY FOR FUZZY MATCHING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Extract all unique words from training data for typo correction\n",
    "all_words = set()\n",
    "for text in df['text'].str.lower():\n",
    "    all_words.update(re.findall(r'\\w+', text))\n",
    "\n",
    "VOCAB = all_words\n",
    "print(f\"‚úì Vocabulary size: {len(VOCAB)} unique words\")\n",
    "print(f\"‚úì Sample words: {list(VOCAB)[:20]}\")\n",
    "\n",
    "def fuzzy_correct(text: str, cutoff: float = 0.8) -> str:\n",
    "    \"\"\"\n",
    "    Typo correction using difflib (Fuzzy String Matching)\n",
    "    \n",
    "    Algorithm: Levenshtein Distance\n",
    "    - Finds closest matching words from vocabulary\n",
    "    - Corrects typos while preserving sentence structure\n",
    "    \n",
    "    Example: \"blst mesage\" ‚Üí \"blast message\"\n",
    "    \"\"\"\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    corrected = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Find closest match in vocabulary\n",
    "        matches = get_close_matches(word, VOCAB, n=1, cutoff=cutoff)\n",
    "        corrected.append(matches[0] if matches else word)\n",
    "    \n",
    "    # Reconstruct sentence preserving original punctuation\n",
    "    result = text\n",
    "    for orig, corr in zip(words, corrected):\n",
    "        if orig != corr:\n",
    "            result = re.sub(rf'\\b{orig}\\b', corr, result, count=1, flags=re.IGNORECASE)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test fuzzy correction\n",
    "print(\"\\nüß™ Testing Fuzzy Correction:\")\n",
    "test_cases = [\n",
    "    \"blst mesage\",\n",
    "    \"chek number\",\n",
    "    \"craete instance\",\n",
    "    \"shedule mesage\"\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    corrected = fuzzy_correct(test)\n",
    "    print(f\"   '{test}' ‚Üí '{corrected}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117afb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üè∑Ô∏è  ENCODING LABELS\n",
      "================================================================================\n",
      "‚úì Number of classes: 33\n",
      "\n",
      "üìã Intent mapping (first 10):\n",
      "   0: account\n",
      "   1: analytics\n",
      "   2: api\n",
      "   3: cancel\n",
      "   4: chat_view\n",
      "   5: contacts\n",
      "   6: definition\n",
      "   7: files\n",
      "   8: goodbye\n",
      "   9: gratitude\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: LABEL ENCODING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üè∑Ô∏è  ENCODING LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Encode intent labels to numeric values\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['intent'])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "intent_map = dict(enumerate(le.classes_))\n",
    "\n",
    "print(f\"‚úì Number of classes: {num_classes}\")\n",
    "print(f\"\\nüìã Intent mapping (first 10):\")\n",
    "for idx, intent in list(intent_map.items())[:10]:\n",
    "    print(f\"   {idx}: {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cea0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß† GENERATING SENTENCE EMBEDDINGS\n",
      "================================================================================\n",
      "Using: Sentence Transformers (all-MiniLM-L6-v2)\n",
      "This is a neural embedding model (similar to Word2Vec but sentence-level)\n",
      "================================================================================\n",
      "‚úì Loaded embedding model\n",
      "‚úì Embedding dimension: 384\n",
      "\n",
      "üìä Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 58.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generated embeddings: torch.Size([657, 384])\n",
      "   - Shape: (num_samples, embedding_dim)\n",
      "   - Device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 6: SENTENCE EMBEDDINGS (WORD2VEC ALTERNATIVE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß† GENERATING SENTENCE EMBEDDINGS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Using: Sentence Transformers (all-MiniLM-L6-v2)\")\n",
    "print(\"This is a neural embedding model (similar to Word2Vec but sentence-level)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load pre-trained sentence embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"‚úì Loaded embedding model\")\n",
    "print(f\"‚úì Embedding dimension: 384\")\n",
    "\n",
    "# Generate embeddings for all training samples\n",
    "print(\"\\nüìä Encoding training data...\")\n",
    "sentence_embeddings = embedder.encode(\n",
    "    df['text'].tolist(), \n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True\n",
    ").to(device)\n",
    "\n",
    "print(f\"‚úì Generated embeddings: {sentence_embeddings.shape}\")\n",
    "print(f\"   - Shape: (num_samples, embedding_dim)\")\n",
    "print(f\"   - Device: {sentence_embeddings.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c65f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèóÔ∏è  FEEDFORWARD CLASSIFIER ARCHITECTURE\n",
      "================================================================================\n",
      "\n",
      "üìê Model Architecture:\n",
      "EmbeddingClassifier(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=33, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "‚úì Total parameters: 135,713\n",
      "‚úì Model defined successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 7: FEEDFORWARD NETWORK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèóÔ∏è  FEEDFORWARD CLASSIFIER ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple Feedforward Neural Network for Sentence Embeddings\n",
    "    \n",
    "    Why not CNN?\n",
    "    - CNNs are for sequential data (words in sentence)\n",
    "    - We already have holistic sentence embeddings (384-dim vectors)\n",
    "    - Feedforward network is the right architecture for this!\n",
    "    \n",
    "    Architecture:\n",
    "    1. Input: 384-dim sentence embedding\n",
    "    2. Hidden Layer 1: 384 ‚Üí 256 (ReLU + Dropout)\n",
    "    3. Hidden Layer 2: 256 ‚Üí 128 (ReLU + Dropout)\n",
    "    4. Output Layer: 128 ‚Üí num_classes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim=384, num_classes=num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Linear(embed_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 384)\n",
    "        return self.network(x)  # (batch_size, num_classes)\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nüìê Model Architecture:\")\n",
    "model = EmbeddingClassifier()\n",
    "print(model)\n",
    "print(f\"\\n‚úì Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\"‚úì Model defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479cfcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ TRAINING MLP MODEL\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìö PREPARING TRAINING DATA\n",
      "================================================================================\n",
      "‚úì X shape: torch.Size([657, 384])\n",
      "‚úì y shape: torch.Size([657])\n",
      "\n",
      "‚úì Training samples: 525\n",
      "‚úì Validation samples: 132\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è  TRAINING LOOP (WITH PROPER BATCHING!)\n",
      "================================================================================\n",
      "\n",
      "Epoch | Train Acc | Train Loss | Val Acc | Val Loss\n",
      "-----------------------------------------------------------------\n",
      "    0 |    0.0533 |     3.4865 |  0.1439 |   3.4596\n",
      "    5 |    0.7067 |     1.6769 |  0.7955 |   1.3960\n",
      "   10 |    0.9067 |     0.4939 |  0.9091 |   0.5397\n",
      "   15 |    0.9429 |     0.2574 |  0.8712 |   0.4169\n",
      "   20 |    0.9733 |     0.1672 |  0.9015 |   0.3774\n",
      "   25 |    0.9848 |     0.1021 |  0.9091 |   0.3528\n",
      "   30 |    0.9848 |     0.0891 |  0.8939 |   0.3578\n",
      "   35 |    0.9829 |     0.0692 |  0.9167 |   0.3336\n",
      "   40 |    0.9848 |     0.0649 |  0.9091 |   0.3472\n",
      "   45 |    0.9886 |     0.0446 |  0.9091 |   0.3555\n",
      "   49 |    0.9829 |     0.0515 |  0.9242 |   0.3709\n",
      "\n",
      "================================================================================\n",
      "‚úì Training Complete!\n",
      "‚úì Best Validation Accuracy: 0.9242 (92.42%)\n",
      "‚úì Model saved to: chattea.pth\n",
      "================================================================================\n",
      "\n",
      "üìä Final Performance:\n",
      "   Training Accuracy:   0.9943 (99.43%)\n",
      "   Validation Accuracy: 0.9242 (92.42%)\n",
      "\n",
      "‚úì Model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 8: TRAIN OR LOAD MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ TRAINING MLP MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_path = \"chattea.pth\"\n",
    "\n",
    "# Force retrain\n",
    "import os\n",
    "if os.path.exists(model_path):\n",
    "    os.remove(model_path)\n",
    "    print(\"‚ö†Ô∏è  Deleted old model - retraining from scratch!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö PREPARING TRAINING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use the pre-computed embeddings from Cell 6\n",
    "X = sentence_embeddings.to(device)\n",
    "y = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "\n",
    "print(f\"‚úì X shape: {X.shape}\")\n",
    "print(f\"‚úì y shape: {y.shape}\")\n",
    "\n",
    "# Train/validation split (stratified)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    list(range(len(X))),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y.cpu()\n",
    ")\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_val = X[val_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "print(f\"\\n‚úì Training samples: {len(X_train)}\")\n",
    "print(f\"‚úì Validation samples: {len(X_val)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèãÔ∏è  TRAINING LOOP (WITH PROPER BATCHING!)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize model\n",
    "model = EmbeddingClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Lower LR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50  # More epochs\n",
    "\n",
    "# Create mini-batches\n",
    "def create_batches(X, y, batch_size):\n",
    "    \"\"\"Create mini-batches for training\"\"\"\n",
    "    indices = torch.randperm(len(X))\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        batch_idx = indices[i:i+batch_size]\n",
    "        yield X[batch_idx], y[batch_idx]\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nEpoch | Train Acc | Train Loss | Val Acc | Val Loss\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ========== TRAINING ==========\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_X, batch_y in create_batches(X_train, y_train, BATCH_SIZE):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (outputs.argmax(1) == batch_y).sum().item()\n",
    "        train_total += len(batch_y)\n",
    "    \n",
    "    train_acc = train_correct / train_total\n",
    "    train_loss = train_loss / (len(X_train) // BATCH_SIZE + 1)\n",
    "    \n",
    "    # ========== VALIDATION ==========\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val).item()\n",
    "        val_acc = (val_outputs.argmax(1) == y_val).float().mean().item()\n",
    "    \n",
    "    # Print progress\n",
    "    if epoch % 5 == 0 or epoch == EPOCHS - 1:\n",
    "        print(f\"{epoch:5d} | {train_acc:9.4f} | {train_loss:10.4f} | {val_acc:7.4f} | {val_loss:8.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úì Training Complete!\")\n",
    "print(f\"‚úì Best Validation Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "print(f\"‚úì Model saved to: {model_path}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Final check on training data\n",
    "with torch.no_grad():\n",
    "    final_train_pred = model(X_train).argmax(1)\n",
    "    final_train_acc = (final_train_pred == y_train).float().mean().item()\n",
    "    \n",
    "    final_val_pred = model(X_val).argmax(1)\n",
    "    final_val_acc = (final_val_pred == y_val).float().mean().item()\n",
    "\n",
    "print(f\"\\nüìä Final Performance:\")\n",
    "print(f\"   Training Accuracy:   {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "print(f\"   Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úì Model ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95cf782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üì± PHONE NUMBER EXTRACTION (Named Entity Recognition)\n",
      "================================================================================\n",
      "\n",
      "üß™ Testing Phone Extraction:\n",
      "   'check 08123456789' ‚Üí 08123456789\n",
      "   'verify 628123456789' ‚Üí 08123456789\n",
      "   'validate +628123456789' ‚Üí 08123456789\n",
      "   'is 0812-3456-789 valid' ‚Üí None\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: PHONE NUMBER EXTRACTION (NER)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üì± PHONE NUMBER EXTRACTION (Named Entity Recognition)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Regex pattern for Indonesian phone numbers\n",
    "PHONE_PATTERN = re.compile(\n",
    "    r'(\\b08[1-9]\\d{7,12}\\b|\\b628[1-9]\\d{7,12}\\b|\\b\\+628[1-9]\\d{7,12}\\b)', \n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def extract_phone(text):\n",
    "    \"\"\"\n",
    "    Extract and normalize Indonesian phone numbers\n",
    "    \n",
    "    Supports formats:\n",
    "    - 08123456789 (local)\n",
    "    - 628123456789 (international without +)\n",
    "    - +628123456789 (international with +)\n",
    "    \n",
    "    Returns normalized format: 08xxxxxxxxxx\n",
    "    \"\"\"\n",
    "    phone_match = PHONE_PATTERN.search(text)\n",
    "    \n",
    "    if phone_match:\n",
    "        num = phone_match.group(0).replace(\" \", \"\").replace(\"-\", \"\")\n",
    "        \n",
    "        if num.startswith(\"08\"):\n",
    "            return num\n",
    "        elif num.startswith(\"628\"):\n",
    "            return \"0\" + num[2:]\n",
    "        elif num.startswith(\"+628\"):\n",
    "            return \"0\" + num[3:]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test phone extraction\n",
    "print(\"\\nüß™ Testing Phone Extraction:\")\n",
    "test_phones = [\n",
    "    \"check 08123456789\",\n",
    "    \"verify 628123456789\",\n",
    "    \"validate +628123456789\",\n",
    "    \"is 0812-3456-789 valid\"\n",
    "]\n",
    "\n",
    "for test in test_phones:\n",
    "    phone = extract_phone(test)\n",
    "    print(f\"   '{test}' ‚Üí {phone}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aadc9d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üí¨ CHAT INFERENCE FUNCTION\n",
      "================================================================================\n",
      "‚úì Chat function ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: MAIN CHAT FUNCTION (INFERENCE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí¨ CHAT INFERENCE FUNCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def get_chattea_reply(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Main chatbot inference function\n",
    "    \n",
    "    Pipeline:\n",
    "    1. Rule-based filters (greetings, goodbyes)\n",
    "    2. Phone number extraction (if applicable)\n",
    "    3. CNN classification with confidence check\n",
    "    4. Retrieval fallback (if low confidence)\n",
    "    5. Response generation\n",
    "    \n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        \n",
    "    Returns:\n",
    "        Bot's response\n",
    "    \"\"\"\n",
    "    text = user_input.strip().lower()\n",
    "    \n",
    "    # ==================== RULE-BASED FILTERS ====================\n",
    "    # Quick responses for common greetings\n",
    "    if any(g in text for g in [\"hai\", \"halo\", \"hello\", \"hi\", \"hey\", \"pagi\", \"siang\", \"malam\"]):\n",
    "        return RESPONSES[\"greeting\"][\"en\"]\n",
    "    \n",
    "    if any(g in text for g in [\"bye\", \"goodbye\", \"dadah\", \"sampai jumpa\"]):\n",
    "        return RESPONSES[\"goodbye\"][\"en\"]\n",
    "    \n",
    "    # ==================== PHONE EXTRACTION ====================\n",
    "    extracted_phone = extract_phone(user_input)\n",
    "    \n",
    "    # ==================== EMBEDDING + PREDICTION ====================\n",
    "    with torch.no_grad():\n",
    "        # Encode user input\n",
    "        user_emb = embedder.encode(user_input, convert_to_tensor=True).to(device)\n",
    "        user_emb = user_emb.unsqueeze(0)  # (1, 384)\n",
    "        \n",
    "        # MLP prediction\n",
    "        logits = model(user_emb)\n",
    "        probs = logits.softmax(1)\n",
    "        confidence = probs.max().item()\n",
    "        intent = intent_map[logits.argmax(1).item()]\n",
    "        \n",
    "        # Retrieval fallback (semantic similarity)\n",
    "        cos_scores = util.cos_sim(user_emb, sentence_embeddings)[0]\n",
    "        best_match_idx = cos_scores.argmax().item()\n",
    "        retrieval_intent = df.iloc[best_match_idx]['intent']\n",
    "        retrieval_score = cos_scores[best_match_idx].item()\n",
    "        \n",
    "        # Choose final intent based on confidence\n",
    "        if confidence > 0.90:\n",
    "            final_intent = intent\n",
    "            source = \"MLP\"\n",
    "        else:\n",
    "            final_intent = retrieval_intent\n",
    "            source = \"Retrieval\"\n",
    "    \n",
    "    # ==================== SPECIAL CASES ====================\n",
    "    # Phone check with extracted number\n",
    "    if final_intent == \"phone_check\" and extracted_phone:\n",
    "        return f\"Checking {extracted_phone}...\\nYes, this number is registered and active on WhatsApp!\\n\\nYou can safely include it in your blast list.\"\n",
    "    \n",
    "    # ==================== RESPONSE GENERATION ====================\n",
    "    response = RESPONSES.get(final_intent, RESPONSES.get(\"help\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    # Handle both dict (bilingual) and string responses\n",
    "    if isinstance(response, dict):\n",
    "        return response.get(\"en\", response.get(\"id\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"‚úì Chat function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0fbf495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß™ TESTING INFERENCE\n",
      "================================================================================\n",
      "\n",
      "Running test queries:\n",
      "\n",
      "üë§ User: hello\n",
      "ü§ñ Bot: Hello! üëã Welcome to Chattea.\n",
      "\n",
      "I'm here to help you navigate features like sending messages, managing...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: what is chattea\n",
      "ü§ñ Bot: Chattea is a WhatsApp marketing automation platform designed for businesses.\n",
      "\n",
      "Key features:\n",
      "‚Ä¢ Send m...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: how to blast message\n",
      "ü§ñ Bot: To send a blast (mass message):\n",
      "\n",
      "1. Go to **Blast Message** ‚Üí **New Blast**\n",
      "2. Select contacts, grou...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: check 08123456789\n",
      "ü§ñ Bot: Checking 08123456789...\n",
      "Yes, this number is registered and active on WhatsApp!\n",
      "\n",
      "You can safely inclu...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: create instance\n",
      "ü§ñ Bot: To create a new WhatsApp instance:\n",
      "\n",
      "1. Open the **Instances** tab\n",
      "2. Click **+ New Instance**\n",
      "3. Ent...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: schedule message\n",
      "ü§ñ Bot: To schedule a message:\n",
      "\n",
      "1. Compose your message normally\n",
      "2. Click the **Schedule (‚è∞)** button\n",
      "3. Sel...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: thanks\n",
      "ü§ñ Bot: You're welcome! üòä Happy to help.\n",
      "If you need anything else, just let me know!\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: goodbye\n",
      "ü§ñ Bot: Thanks for using Chattea! üëã\n",
      "\n",
      "If you need help again, feel free to return anytime.\n",
      "Wishing you succes...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 11: TEST INFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß™ TESTING INFERENCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_queries = [\n",
    "    \"hello\",\n",
    "    \"what is chattea\",\n",
    "    \"how to blast message\",\n",
    "    \"check 08123456789\",\n",
    "    \"create instance\",\n",
    "    \"schedule message\",\n",
    "    \"thanks\",\n",
    "    \"goodbye\"\n",
    "]\n",
    "\n",
    "print(\"\\nRunning test queries:\\n\")\n",
    "for query in test_queries:\n",
    "    print(f\"üë§ User: {query}\")\n",
    "    response = get_chattea_reply(query)\n",
    "    print(f\"ü§ñ Bot: {response[:100]}{'...' if len(response) > 100 else ''}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc463ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä MODEL EVALUATION\n",
      "================================================================================\n",
      "‚úì Validation Accuracy: 0.9242 (92.42%)\n",
      "\n",
      "üìã Per-Intent Performance:\n",
      "   account                       : 0.750 ( 4 samples)\n",
      "   analytics                     : 1.000 ( 4 samples)\n",
      "   api                           : 1.000 ( 4 samples)\n",
      "   cancel                        : 1.000 ( 4 samples)\n",
      "   chat_view                     : 1.000 ( 4 samples)\n",
      "   contacts                      : 1.000 ( 4 samples)\n",
      "   definition                    : 1.000 ( 4 samples)\n",
      "   files                         : 0.750 ( 4 samples)\n",
      "   goodbye                       : 0.750 ( 4 samples)\n",
      "   gratitude                     : 1.000 ( 4 samples)\n",
      "   greeting                      : 1.000 ( 4 samples)\n",
      "   groups                        : 1.000 ( 4 samples)\n",
      "   help                          : 1.000 ( 4 samples)\n",
      "   instance_connect              : 0.750 ( 4 samples)\n",
      "   instance_create               : 1.000 ( 4 samples)\n",
      "   instance_manage               : 1.000 ( 4 samples)\n",
      "   instance_status               : 1.000 ( 4 samples)\n",
      "   message_blast                 : 1.000 ( 4 samples)\n",
      "   message_schedule              : 1.000 ( 4 samples)\n",
      "   message_send                  : 1.000 ( 4 samples)\n",
      "   message_status                : 0.500 ( 4 samples)\n",
      "   navigation                    : 0.500 ( 4 samples)\n",
      "   payment                       : 0.750 ( 4 samples)\n",
      "   phone_check                   : 1.000 ( 4 samples)\n",
      "   platform_info                 : 1.000 ( 4 samples)\n",
      "   pricing                       : 0.750 ( 4 samples)\n",
      "   quota                         : 1.000 ( 4 samples)\n",
      "   security                      : 1.000 ( 4 samples)\n",
      "   settings                      : 1.000 ( 4 samples)\n",
      "   tasks                         : 1.000 ( 4 samples)\n",
      "   templates                     : 1.000 ( 4 samples)\n",
      "   troubleshoot                  : 1.000 ( 4 samples)\n",
      "   warmup                        : 1.000 ( 4 samples)\n",
      "Accuracy on FULL training set: 0.9802\n",
      "\n",
      "================================================================================\n",
      "‚úÖ NOTEBOOK COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Your model is ready to use!\n",
      "‚úì Deleted old model\n",
      "‚úì Cleared GPU cache\n",
      "\n",
      "‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 13: MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä MODEL EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluate on validation set\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    X_all = embedder.encode(df['text'].tolist(), convert_to_tensor=True).to(device)\n",
    "    y_all = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        torch.arange(len(X_all)),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_all.cpu()\n",
    "    )\n",
    "    \n",
    "    X_val = X_all[val_idx].to(device)\n",
    "    y_val = y_all[val_idx].to(device)\n",
    "    \n",
    "    # Predict\n",
    "    val_outputs = model(X_val)\n",
    "    val_preds = val_outputs.argmax(1)\n",
    "    \n",
    "    # Accuracy\n",
    "    val_acc = (val_preds == y_val).float().mean().item()\n",
    "    \n",
    "    print(f\"‚úì Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nüìã Per-Intent Performance:\")\n",
    "    for intent_id in range(num_classes):\n",
    "        intent_name = intent_map[intent_id]\n",
    "        mask = y_val == intent_id\n",
    "        if mask.sum() > 0:\n",
    "            intent_acc = (val_preds[mask] == y_val[mask]).float().mean().item()\n",
    "            count = mask.sum().item()\n",
    "            print(f\"   {intent_name:30s}: {intent_acc:.3f} ({count:2d} samples)\")\n",
    "\n",
    "# Test on ALL training data (should be near perfect)\n",
    "with torch.no_grad():\n",
    "    all_outputs = model(sentence_embeddings.to(device))\n",
    "    all_preds = all_outputs.argmax(1)\n",
    "    all_labels = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    train_acc = (all_preds == all_labels).float().mean().item()\n",
    "    print(f\"Accuracy on FULL training set: {train_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ NOTEBOOK COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nYour model is ready to use!\")\n",
    "\n",
    "# ============================================================================\n",
    "# FRESH START - DELETE EVERYTHING AND RETRAIN\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. Delete saved model\n",
    "if os.path.exists(\"chattea.pth\"):\n",
    "    os.remove(\"chattea.pth\")\n",
    "    print(\"‚úì Deleted old model\")\n",
    "\n",
    "# 2. Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "# 3. Restart notebook kernel (Kernel ‚Üí Restart & Run All)\n",
    "print(\"\\n‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
