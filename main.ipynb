{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d62ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicho\\Documents\\GitHub_Repository\\Python\\chattea-ai\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHATTEA INTENT CLASSIFIER - MLP + SENTENCE TRANSFORMERS\n",
      "================================================================================\n",
      "PyTorch Version: 2.9.1+cu130\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Chattea Intent Classifier - MLP + Sentence Transformers\n",
    "# Complete Working Pipeline in Notebook Format\n",
    "# Ready to run cell by cell!\n",
    "\n",
    "\"\"\"\n",
    "JUPYTER NOTEBOOK STRUCTURE:\n",
    "Run each cell in order (Shift+Enter)\n",
    "\n",
    "Required Files:\n",
    "- chatbot_dataset.csv (text, intent columns)\n",
    "- responses.json (your bilingual responses)\n",
    "\n",
    "Installation:\n",
    "!pip install torch sentence-transformers scikit-learn pandas difflib\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from difflib import get_close_matches\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CHATTEA INTENT CLASSIFIER - MLP + SENTENCE TRANSFORMERS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1978fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Using device: cuda\n",
      "üéÆ GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "üíæ GPU Memory: 8.59 GB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: DEVICE CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - training will use CPU (slower)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7b133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìÇ LOADING DATA\n",
      "================================================================================\n",
      "‚úì Loaded dataset: 2102 samples\n",
      "‚úì Columns: ['text', 'intent']\n",
      "‚úì Unique intents: 14\n",
      "\n",
      "üìä Sample data:\n",
      "                                              text        intent\n",
      "0                          how do i send a message  send_message\n",
      "1            can you send a message to my contacts  send_message\n",
      "2                    i want to send a bulk message  send_message\n",
      "3                                     send message  send_message\n",
      "4                                 how to broadcast  send_message\n",
      "5      i need to send a message to multiple people  send_message\n",
      "6                          can i send messages now  send_message\n",
      "7                          send a whatsapp message  send_message\n",
      "8  how do i send bulk messages to my customer list  send_message\n",
      "9                i want to message all my contacts  send_message\n",
      "\n",
      "üìà Intent distribution:\n",
      "intent\n",
      "send_message        160\n",
      "schedule_message    160\n",
      "filter_number       160\n",
      "what_for            160\n",
      "pricing             160\n",
      "create_instance     159\n",
      "edit_instance       159\n",
      "delete_instance     159\n",
      "edit_group          159\n",
      "create_group        159\n",
      "delete_group        159\n",
      "contact             159\n",
      "unknown             124\n",
      "greeting             65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Loaded responses for 14 intents\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìÇ LOADING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load training dataset\n",
    "df = pd.read_csv(\"chatbot_dataset.csv\")\n",
    "print(f\"‚úì Loaded dataset: {len(df)} samples\")\n",
    "print(f\"‚úì Columns: {list(df.columns)}\")\n",
    "print(f\"‚úì Unique intents: {df['intent'].nunique()}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìä Sample data:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Intent distribution\n",
    "print(\"\\nüìà Intent distribution:\")\n",
    "intent_counts = df['intent'].value_counts()\n",
    "print(intent_counts.head(15))\n",
    "\n",
    "# Load responses\n",
    "with open(\"responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    RESPONSES = json.load(f)\n",
    "print(f\"\\n‚úì Loaded responses for {len(RESPONSES)} intents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76954e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìö BUILDING VOCABULARY FOR FUZZY MATCHING\n",
      "================================================================================\n",
      "‚úì Vocabulary size: 1037 unique words\n",
      "‚úì Sample words: ['automate', 'on', 'enough', 'remind', 'codes', 'emails', 'howdy', 'subscription', 'deletion', 'acquired', 'tier', 'purchase', 'qwerty', 'specific', 'metadata', 'hola', 'i', 'details', 'questions', 'live']\n",
      "\n",
      "üß™ Testing Fuzzy Correction:\n",
      "   'blst mesage' ‚Üí 'blast message'\n",
      "   'chek number' ‚Üí 'check number'\n",
      "   'craete instance' ‚Üí 'create instance'\n",
      "   'shedule mesage' ‚Üí 'schedule message'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: BUILD VOCABULARY FOR FUZZY MATCHING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö BUILDING VOCABULARY FOR FUZZY MATCHING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Extract all unique words from training data for typo correction\n",
    "all_words = set()\n",
    "for text in df['text'].str.lower():\n",
    "    all_words.update(re.findall(r'\\w+', text))\n",
    "\n",
    "VOCAB = all_words\n",
    "print(f\"‚úì Vocabulary size: {len(VOCAB)} unique words\")\n",
    "print(f\"‚úì Sample words: {list(VOCAB)[:20]}\")\n",
    "\n",
    "def fuzzy_correct(text: str, cutoff: float = 0.8) -> str:\n",
    "    \"\"\"\n",
    "    Typo correction using difflib (Fuzzy String Matching)\n",
    "    \n",
    "    Algorithm: Levenshtein Distance\n",
    "    - Finds closest matching words from vocabulary\n",
    "    - Corrects typos while preserving sentence structure\n",
    "    \n",
    "    Example: \"blst mesage\" ‚Üí \"blast message\"\n",
    "    \"\"\"\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    corrected = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Find closest match in vocabulary\n",
    "        matches = get_close_matches(word, VOCAB, n=1, cutoff=cutoff)\n",
    "        corrected.append(matches[0] if matches else word)\n",
    "    \n",
    "    # Reconstruct sentence preserving original punctuation\n",
    "    result = text\n",
    "    for orig, corr in zip(words, corrected):\n",
    "        if orig != corr:\n",
    "            result = re.sub(rf'\\b{orig}\\b', corr, result, count=1, flags=re.IGNORECASE)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test fuzzy correction\n",
    "print(\"\\nüß™ Testing Fuzzy Correction:\")\n",
    "test_cases = [\n",
    "    \"blst mesage\",\n",
    "    \"chek number\",\n",
    "    \"craete instance\",\n",
    "    \"shedule mesage\"\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    corrected = fuzzy_correct(test)\n",
    "    print(f\"   '{test}' ‚Üí '{corrected}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117afb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üè∑Ô∏è  ENCODING LABELS\n",
      "================================================================================\n",
      "‚úì Number of classes: 14\n",
      "\n",
      "üìã Intent mapping (first 10):\n",
      "   0: contact\n",
      "   1: create_group\n",
      "   2: create_instance\n",
      "   3: delete_group\n",
      "   4: delete_instance\n",
      "   5: edit_group\n",
      "   6: edit_instance\n",
      "   7: filter_number\n",
      "   8: greeting\n",
      "   9: pricing\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: LABEL ENCODING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üè∑Ô∏è  ENCODING LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Encode intent labels to numeric values\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['intent'])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "intent_map = dict(enumerate(le.classes_))\n",
    "\n",
    "print(f\"‚úì Number of classes: {num_classes}\")\n",
    "print(f\"\\nüìã Intent mapping (first 10):\")\n",
    "for idx, intent in list(intent_map.items())[:10]:\n",
    "    print(f\"   {idx}: {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cea0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß† GENERATING SENTENCE EMBEDDINGS\n",
      "================================================================================\n",
      "Using: Sentence Transformers (all-MiniLM-L6-v2)\n",
      "This is a neural embedding model (similar to Word2Vec but sentence-level)\n",
      "================================================================================\n",
      "‚úì Loaded embedding model\n",
      "‚úì Embedding dimension: 384\n",
      "\n",
      "üìä Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:01<00:00, 59.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generated embeddings: torch.Size([2102, 384])\n",
      "   - Shape: (num_samples, embedding_dim)\n",
      "   - Device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 6: SENTENCE EMBEDDINGS (WORD2VEC ALTERNATIVE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß† GENERATING SENTENCE EMBEDDINGS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Using: Sentence Transformers (all-MiniLM-L6-v2)\")\n",
    "print(\"This is a neural embedding model (similar to Word2Vec but sentence-level)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load pre-trained sentence embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"‚úì Loaded embedding model\")\n",
    "print(f\"‚úì Embedding dimension: 384\")\n",
    "\n",
    "# Generate embeddings for all training samples\n",
    "print(\"\\nüìä Encoding training data...\")\n",
    "sentence_embeddings = embedder.encode(\n",
    "    df['text'].tolist(), \n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True\n",
    ").to(device)\n",
    "\n",
    "print(f\"‚úì Generated embeddings: {sentence_embeddings.shape}\")\n",
    "print(f\"   - Shape: (num_samples, embedding_dim)\")\n",
    "print(f\"   - Device: {sentence_embeddings.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c65f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèóÔ∏è  FEEDFORWARD CLASSIFIER ARCHITECTURE\n",
      "================================================================================\n",
      "\n",
      "üìê Model Architecture:\n",
      "EmbeddingClassifier(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=14, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "‚úì Total parameters: 133,262\n",
      "‚úì Model defined successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 7: FEEDFORWARD NETWORK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèóÔ∏è  FEEDFORWARD CLASSIFIER ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple Feedforward Neural Network for Sentence Embeddings\n",
    "    \n",
    "    Why not CNN?\n",
    "    - CNNs are for sequential data (words in sentence)\n",
    "    - We already have holistic sentence embeddings (384-dim vectors)\n",
    "    - Feedforward network is the right architecture for this!\n",
    "    \n",
    "    Architecture:\n",
    "    1. Input: 384-dim sentence embedding\n",
    "    2. Hidden Layer 1: 384 ‚Üí 256 (ReLU + Dropout)\n",
    "    3. Hidden Layer 2: 256 ‚Üí 128 (ReLU + Dropout)\n",
    "    4. Output Layer: 128 ‚Üí num_classes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim=384, num_classes=num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Linear(embed_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 384)\n",
    "        return self.network(x)  # (batch_size, num_classes)\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nüìê Model Architecture:\")\n",
    "model = EmbeddingClassifier()\n",
    "print(model)\n",
    "print(f\"\\n‚úì Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\"‚úì Model defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479cfcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ TRAINING MLP MODEL\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìö PREPARING TRAINING DATA\n",
      "================================================================================\n",
      "‚úì X shape: torch.Size([2102, 384])\n",
      "‚úì y shape: torch.Size([2102])\n",
      "\n",
      "‚úì Training samples: 1681\n",
      "‚úì Validation samples: 421\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è  TRAINING LOOP (WITH PROPER BATCHING!)\n",
      "================================================================================\n",
      "\n",
      "Epoch | Train Acc | Train Loss | Val Acc | Val Loss\n",
      "-----------------------------------------------------------------\n",
      "    0 |    0.4390 |     2.3088 |  0.7363 |   1.4189\n",
      "    5 |    0.9798 |     0.0797 |  0.9929 |   0.0459\n",
      "   10 |    0.9958 |     0.0249 |  0.9929 |   0.0272\n",
      "   15 |    0.9976 |     0.0147 |  0.9929 |   0.0204\n",
      "   20 |    0.9982 |     0.0092 |  0.9976 |   0.0176\n",
      "   25 |    0.9988 |     0.0057 |  0.9952 |   0.0229\n",
      "   30 |    1.0000 |     0.0031 |  0.9976 |   0.0128\n",
      "   35 |    0.9994 |     0.0036 |  0.9976 |   0.0131\n",
      "   40 |    1.0000 |     0.0016 |  0.9976 |   0.0180\n",
      "   45 |    1.0000 |     0.0016 |  0.9976 |   0.0165\n",
      "   49 |    1.0000 |     0.0009 |  0.9976 |   0.0144\n",
      "\n",
      "================================================================================\n",
      "‚úì Training Complete!\n",
      "‚úì Best Validation Accuracy: 0.9976 (99.76%)\n",
      "‚úì Model saved to: chattea.pth\n",
      "================================================================================\n",
      "\n",
      "üìä Final Performance:\n",
      "   Training Accuracy:   0.9988 (99.88%)\n",
      "   Validation Accuracy: 0.9976 (99.76%)\n",
      "\n",
      "‚úì Model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 8: TRAIN OR LOAD MLP MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ TRAINING MLP MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_path = \"chattea.pth\"\n",
    "\n",
    "# Force retrain\n",
    "import os\n",
    "if os.path.exists(model_path):\n",
    "    os.remove(model_path)\n",
    "    print(\"‚ö†Ô∏è  Deleted old model - retraining from scratch!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö PREPARING TRAINING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use the pre-computed embeddings from Cell 6\n",
    "X = sentence_embeddings.to(device)\n",
    "y = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "\n",
    "print(f\"‚úì X shape: {X.shape}\")\n",
    "print(f\"‚úì y shape: {y.shape}\")\n",
    "\n",
    "# Train/validation split (stratified)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    list(range(len(X))),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y.cpu()\n",
    ")\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_val = X[val_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "print(f\"\\n‚úì Training samples: {len(X_train)}\")\n",
    "print(f\"‚úì Validation samples: {len(X_val)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèãÔ∏è  TRAINING LOOP (WITH PROPER BATCHING!)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize model\n",
    "model = EmbeddingClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Lower LR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50  # More epochs\n",
    "\n",
    "# Create mini-batches\n",
    "def create_batches(X, y, batch_size):\n",
    "    \"\"\"Create mini-batches for training\"\"\"\n",
    "    indices = torch.randperm(len(X))\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        batch_idx = indices[i:i+batch_size]\n",
    "        yield X[batch_idx], y[batch_idx]\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nEpoch | Train Acc | Train Loss | Val Acc | Val Loss\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ========== TRAINING ==========\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_X, batch_y in create_batches(X_train, y_train, BATCH_SIZE):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (outputs.argmax(1) == batch_y).sum().item()\n",
    "        train_total += len(batch_y)\n",
    "    \n",
    "    train_acc = train_correct / train_total\n",
    "    train_loss = train_loss / (len(X_train) // BATCH_SIZE + 1)\n",
    "    \n",
    "    # ========== VALIDATION ==========\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val).item()\n",
    "        val_acc = (val_outputs.argmax(1) == y_val).float().mean().item()\n",
    "    \n",
    "    # Print progress\n",
    "    if epoch % 5 == 0 or epoch == EPOCHS - 1:\n",
    "        print(f\"{epoch:5d} | {train_acc:9.4f} | {train_loss:10.4f} | {val_acc:7.4f} | {val_loss:8.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úì Training Complete!\")\n",
    "print(f\"‚úì Best Validation Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "print(f\"‚úì Model saved to: {model_path}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Final check on training data\n",
    "with torch.no_grad():\n",
    "    final_train_pred = model(X_train).argmax(1)\n",
    "    final_train_acc = (final_train_pred == y_train).float().mean().item()\n",
    "    \n",
    "    final_val_pred = model(X_val).argmax(1)\n",
    "    final_val_acc = (final_val_pred == y_val).float().mean().item()\n",
    "\n",
    "print(f\"\\nüìä Final Performance:\")\n",
    "print(f\"   Training Accuracy:   {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "print(f\"   Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úì Model ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aadc9d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üí¨ CHAT INFERENCE FUNCTION\n",
      "================================================================================\n",
      "‚úì Chat function ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: MAIN CHAT FUNCTION (INFERENCE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí¨ CHAT INFERENCE FUNCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def get_chattea_reply(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Main chatbot inference function\n",
    "    \n",
    "    Pipeline:\n",
    "    1. Rule-based filters (greetings, goodbyes)\n",
    "    2. Phone number extraction (if applicable)\n",
    "    3. CNN classification with confidence check\n",
    "    4. Retrieval fallback (if low confidence)\n",
    "    5. Response generation\n",
    "    \n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        \n",
    "    Returns:\n",
    "        Bot's response\n",
    "    \"\"\"\n",
    "    text = user_input.strip().lower()\n",
    "    \n",
    "    # ==================== RULE-BASED FILTERS ====================\n",
    "    # Quick responses for common greetings\n",
    "    if any(g in text for g in [\"hai\", \"halo\", \"hello\", \"hi\", \"hey\", \"pagi\", \"siang\", \"malam\"]):\n",
    "        return RESPONSES[\"greeting\"][\"en\"]\n",
    "    \n",
    "    if any(g in text for g in [\"bye\", \"goodbye\", \"dadah\", \"sampai jumpa\"]):\n",
    "        return RESPONSES[\"unknown\"][\"en\"]\n",
    "    \n",
    "    # ==================== EMBEDDING + PREDICTION ====================\n",
    "    with torch.no_grad():\n",
    "        # Encode user input\n",
    "        user_emb = embedder.encode(user_input, convert_to_tensor=True).to(device)\n",
    "        user_emb = user_emb.unsqueeze(0)  # (1, 384)\n",
    "        \n",
    "        # MLP prediction\n",
    "        logits = model(user_emb)\n",
    "        probs = logits.softmax(1)\n",
    "        confidence = probs.max().item()\n",
    "        intent = intent_map[logits.argmax(1).item()]\n",
    "        \n",
    "        # Retrieval fallback (semantic similarity)\n",
    "        cos_scores = util.cos_sim(user_emb, sentence_embeddings)[0]\n",
    "        best_match_idx = cos_scores.argmax().item()\n",
    "        retrieval_intent = df.iloc[best_match_idx]['intent']\n",
    "        retrieval_score = cos_scores[best_match_idx].item()\n",
    "        \n",
    "        # Choose final intent based on confidence\n",
    "        if confidence > 0.90:\n",
    "            final_intent = intent\n",
    "            source = \"MLP\"\n",
    "        else:\n",
    "            final_intent = retrieval_intent\n",
    "            source = \"Retrieval\"\n",
    "    \n",
    "    # ==================== SPECIAL CASES ====================\n",
    "\n",
    "    # ==================== RESPONSE GENERATION ====================\n",
    "    response = RESPONSES.get(final_intent, RESPONSES.get(\"help\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    # Handle both dict (bilingual) and string responses\n",
    "    if isinstance(response, dict):\n",
    "        return response.get(\"en\", response.get(\"id\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"‚úì Chat function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0fbf495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß™ TESTING INFERENCE\n",
      "================================================================================\n",
      "\n",
      "Running test queries:\n",
      "\n",
      "üë§ User: hello\n",
      "ü§ñ Bot: Hello! üëã Welcome to Chattea.\n",
      "\n",
      "I'm here to help you navigate features like sending messages, managing...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: what is chattea\n",
      "ü§ñ Bot: Chattea is a WhatsApp marketing automation platform designed for businesses.\n",
      "\n",
      "üéØ Key features:\n",
      "‚Ä¢ Send...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: how to blast message\n",
      "ü§ñ Bot: To send a message:\n",
      "\n",
      "1. Choose an active instance\n",
      "2. Enter the destination number (e.g., 628123456789...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: check 08123456789\n",
      "ü§ñ Bot: To filter/check phone numbers:\n",
      "\n",
      "1. Open **Tools** ‚Üí **Phone Checker**\n",
      "2. Enter a phone number or upl...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: create instance\n",
      "ü§ñ Bot: To create a new WhatsApp instance:\n",
      "\n",
      "1. Open the **Instances** tab\n",
      "2. Click **+ New Instance**\n",
      "3. Ent...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: schedule message\n",
      "ü§ñ Bot: To schedule a message:\n",
      "\n",
      "1. Compose your message normally\n",
      "2. Click the **Schedule (‚è∞)** button\n",
      "3. Sel...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: thanks\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: goodbye\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 11: TEST INFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß™ TESTING INFERENCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_queries = [\n",
    "    \"hello\",\n",
    "    \"what is chattea\",\n",
    "    \"how to blast message\",\n",
    "    \"check 08123456789\",\n",
    "    \"create instance\",\n",
    "    \"schedule message\",\n",
    "    \"thanks\",\n",
    "    \"goodbye\"\n",
    "]\n",
    "\n",
    "print(\"\\nRunning test queries:\\n\")\n",
    "for query in test_queries:\n",
    "    print(f\"üë§ User: {query}\")\n",
    "    response = get_chattea_reply(query)\n",
    "    print(f\"ü§ñ Bot: {response[:100]}{'...' if len(response) > 100 else ''}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc463ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä MODEL EVALUATION\n",
      "================================================================================\n",
      "‚úì Validation Accuracy: 0.9976 (99.76%)\n",
      "\n",
      "üìã Per-Intent Performance:\n",
      "   contact                       : 1.000 (32 samples)\n",
      "   create_group                  : 1.000 (32 samples)\n",
      "   create_instance               : 1.000 (32 samples)\n",
      "   delete_group                  : 1.000 (32 samples)\n",
      "   delete_instance               : 1.000 (32 samples)\n",
      "   edit_group                    : 1.000 (32 samples)\n",
      "   edit_instance                 : 1.000 (32 samples)\n",
      "   filter_number                 : 1.000 (32 samples)\n",
      "   greeting                      : 1.000 (13 samples)\n",
      "   pricing                       : 1.000 (32 samples)\n",
      "   schedule_message              : 1.000 (32 samples)\n",
      "   send_message                  : 1.000 (32 samples)\n",
      "   unknown                       : 1.000 (24 samples)\n",
      "   what_for                      : 0.969 (32 samples)\n",
      "Accuracy on FULL training set: 0.9986\n",
      "\n",
      "================================================================================\n",
      "‚úÖ NOTEBOOK COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Your model is ready to use!\n",
      "‚úì Deleted old model\n",
      "‚úì Cleared GPU cache\n",
      "\n",
      "‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 13: MLP MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä MODEL EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluate on validation set\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    X_all = embedder.encode(df['text'].tolist(), convert_to_tensor=True).to(device)\n",
    "    y_all = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        torch.arange(len(X_all)),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_all.cpu()\n",
    "    )\n",
    "    \n",
    "    X_val = X_all[val_idx].to(device)\n",
    "    y_val = y_all[val_idx].to(device)\n",
    "    \n",
    "    # Predict\n",
    "    val_outputs = model(X_val)\n",
    "    val_preds = val_outputs.argmax(1)\n",
    "    \n",
    "    # Accuracy\n",
    "    val_acc = (val_preds == y_val).float().mean().item()\n",
    "    \n",
    "    print(f\"‚úì Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nüìã Per-Intent Performance:\")\n",
    "    for intent_id in range(num_classes):\n",
    "        intent_name = intent_map[intent_id]\n",
    "        mask = y_val == intent_id\n",
    "        if mask.sum() > 0:\n",
    "            intent_acc = (val_preds[mask] == y_val[mask]).float().mean().item()\n",
    "            count = mask.sum().item()\n",
    "            print(f\"   {intent_name:30s}: {intent_acc:.3f} ({count:2d} samples)\")\n",
    "\n",
    "# Test on ALL training data (should be near perfect)\n",
    "with torch.no_grad():\n",
    "    all_outputs = model(sentence_embeddings.to(device))\n",
    "    all_preds = all_outputs.argmax(1)\n",
    "    all_labels = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    train_acc = (all_preds == all_labels).float().mean().item()\n",
    "    print(f\"Accuracy on FULL training set: {train_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ NOTEBOOK COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nYour model is ready to use!\")\n",
    "\n",
    "# ============================================================================\n",
    "# FRESH START - DELETE EVERYTHING AND RETRAIN\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. Delete saved model\n",
    "if os.path.exists(\"chattea.pth\"):\n",
    "    os.remove(\"chattea.pth\")\n",
    "    print(\"‚úì Deleted old model\")\n",
    "\n",
    "# 2. Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "# 3. Restart notebook kernel (Kernel ‚Üí Restart & Run All)\n",
    "print(\"\\n‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d3cfee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèóÔ∏è  CNN MODEL ARCHITECTURE\n",
      "================================================================================\n",
      "\n",
      "üìê Model Architecture:\n",
      "TextCNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv1d(1, 128, kernel_size=(3,), stride=(1,))\n",
      "    (1): Conv1d(1, 128, kernel_size=(4,), stride=(1,))\n",
      "    (2): Conv1d(1, 128, kernel_size=(5,), stride=(1,))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=384, out_features=14, bias=True)\n",
      ")\n",
      "\n",
      "‚úì Model defined successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 7: CNN MODEL ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèóÔ∏è  CNN MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for Text Classification\n",
    "    \n",
    "    Architecture:\n",
    "    1. Input: Sentence embeddings (384-dim vectors)\n",
    "    2. Multiple Conv1D layers with different kernel sizes (3, 4, 5)\n",
    "       - Detects patterns of different n-gram lengths\n",
    "    3. Max pooling: Extract most important features\n",
    "    4. Dropout: Prevent overfitting (40%)\n",
    "    5. Fully connected layer: Final classification\n",
    "    \n",
    "    Why CNN for text?\n",
    "    - Detects local patterns (like phrases)\n",
    "    - Translation invariant (same pattern anywhere in text)\n",
    "    - Faster than RNN/LSTM\n",
    "    - Simpler than Transformers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim=384, num_classes=num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multiple convolution layers with different kernel sizes\n",
    "        # This captures n-grams of different lengths\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=1, out_channels=128, kernel_size=k) \n",
    "            for k in [3, 4, 5]\n",
    "        ])\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(128 * 3, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 384)\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, 384)\n",
    "        \n",
    "        # Apply convolutions and max pooling\n",
    "        convs = [F.relu(conv(x)).max(dim=2)[0] for conv in self.convs]\n",
    "        \n",
    "        # Concatenate all conv outputs\n",
    "        x = torch.cat(convs, dim=1)  # (batch_size, 128*3)\n",
    "        \n",
    "        # Dropout and classification\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nüìê Model Architecture:\")\n",
    "print(TextCNN())\n",
    "print(\"\\n‚úì Model defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe6bbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ TRAINING CNN MODEL\n",
      "================================================================================\n",
      "‚ö†Ô∏è  No pre-trained model found. Training from scratch...\n",
      "\n",
      "================================================================================\n",
      "üìö PREPARING TRAINING DATA\n",
      "================================================================================\n",
      "‚úì X shape: torch.Size([2102, 384])\n",
      "‚úì y shape: torch.Size([2102])\n",
      "\n",
      "‚úì Training samples: 1681\n",
      "‚úì Validation samples: 421\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è  TRAINING LOOP\n",
      "================================================================================\n",
      "\n",
      "Epoch | Accuracy | Loss\n",
      "----------------------------------------\n",
      "    0 |   0.0803 |   2.6533\n",
      "    5 |   0.0761 |   2.6305\n",
      "   10 |   0.0773 |   2.6258\n",
      "   15 |   0.0714 |   2.6232\n",
      "   20 |   0.0922 |   2.6191\n",
      "   25 |   0.0886 |   2.6152\n",
      "\n",
      "================================================================================\n",
      "‚úì Final Training Accuracy: 0.0922 (9.22%)\n",
      "‚úì Final Validation Accuracy: 0.0903 (9.03%)\n",
      "================================================================================\n",
      "\n",
      "‚úì Model saved to: cnn_chattea.pth\n",
      "\n",
      "‚úì Model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 8: TRAIN OR LOAD CNN MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ TRAINING CNN MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_path = \"cnn_chattea.pth\"\n",
    "\n",
    "try:\n",
    "    # Try to load pre-trained model\n",
    "    cnn_model = TextCNN().to(device)\n",
    "    cnn_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(\"‚úì Loaded pre-trained CNN model from\", model_path)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è  No pre-trained model found. Training from scratch...\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìö PREPARING TRAINING DATA\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Encode all texts\n",
    "    X = embedder.encode(df['text'].tolist(), convert_to_tensor=True).to(device)\n",
    "    y = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    print(f\"‚úì X shape: {X.shape}\")\n",
    "    print(f\"‚úì y shape: {y.shape}\")\n",
    "    \n",
    "    # Train/validation split (stratified)\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        torch.arange(len(X)),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y.cpu()  # Stratify to maintain class distribution\n",
    "    )\n",
    "    \n",
    "    X_train = X[train_idx].to(device)\n",
    "    X_val = X[val_idx].to(device)\n",
    "    y_train = y[train_idx].to(device)\n",
    "    y_val = y[val_idx].to(device)\n",
    "    \n",
    "    print(f\"\\n‚úì Training samples: {len(X_train)}\")\n",
    "    print(f\"‚úì Validation samples: {len(X_val)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üèãÔ∏è  TRAINING LOOP\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Initialize model\n",
    "    cnn_model = TextCNN().to(device)\n",
    "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.002)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    cnn_model.train()\n",
    "    print(\"\\nEpoch | Accuracy | Loss\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for epoch in range(30):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = cnn_model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = (outputs.argmax(1) == y_train).float().mean().item()\n",
    "        \n",
    "        # Print progress every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"{epoch:5d} | {acc:8.4f} | {loss.item():8.4f}\")\n",
    "    \n",
    "    # Final training accuracy\n",
    "    with torch.no_grad():\n",
    "        outputs = cnn_model(X_train)\n",
    "        train_acc = (outputs.argmax(1) == y_train).float().mean().item()\n",
    "        \n",
    "        # Validation accuracy\n",
    "        val_outputs = cnn_model(X_val)\n",
    "        val_acc = (val_outputs.argmax(1) == y_val).float().mean().item()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"‚úì Final Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "    print(f\"‚úì Final Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(cnn_model.state_dict(), model_path)\n",
    "    print(f\"\\n‚úì Model saved to: {model_path}\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "cnn_model.eval()\n",
    "print(\"\\n‚úì Model ready for inference!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d8b4ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üí¨ CHAT INFERENCE FUNCTION\n",
      "================================================================================\n",
      "‚úì Chat function ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: MAIN CHAT FUNCTION (INFERENCE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí¨ CHAT INFERENCE FUNCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def get_chattea_reply(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Main chatbot inference function\n",
    "    \n",
    "    Pipeline:\n",
    "    1. Rule-based filters (greetings, goodbyes)\n",
    "    2. Phone number extraction (if applicable)\n",
    "    3. CNN classification with confidence check\n",
    "    4. Retrieval fallback (if low confidence)\n",
    "    5. Response generation\n",
    "    \n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        \n",
    "    Returns:\n",
    "        Bot's response\n",
    "    \"\"\"\n",
    "    text = user_input.strip().lower()\n",
    "    \n",
    "    # ==================== RULE-BASED FILTERS ====================\n",
    "    # Quick responses for common greetings\n",
    "    if any(g in text for g in [\"hai\", \"halo\", \"hello\", \"hi\", \"hey\", \"pagi\", \"siang\", \"malam\"]):\n",
    "        return RESPONSES[\"greeting\"][\"en\"]\n",
    "    \n",
    "    if any(g in text for g in [\"bye\", \"goodbye\", \"dadah\", \"sampai jumpa\"]):\n",
    "        return RESPONSES[\"unknown\"][\"en\"]\n",
    "    \n",
    "    # ==================== EMBEDDING + PREDICTION ====================\n",
    "    with torch.no_grad():\n",
    "        # Encode user input\n",
    "        user_emb = embedder.encode(user_input, convert_to_tensor=True).to(device)\n",
    "        user_emb = user_emb.unsqueeze(0)  # (1, 384)\n",
    "        \n",
    "        # CNN prediction\n",
    "        cnn_logits = cnn_model(user_emb)\n",
    "        cnn_probs = cnn_logits.softmax(1)\n",
    "        cnn_confidence = cnn_probs.max().item()\n",
    "        cnn_intent = intent_map[cnn_logits.argmax(1).item()]\n",
    "        \n",
    "        # Retrieval fallback (semantic similarity)\n",
    "        cos_scores = util.cos_sim(user_emb, sentence_embeddings)[0]\n",
    "        best_match_idx = cos_scores.argmax().item()\n",
    "        retrieval_intent = df.iloc[best_match_idx]['intent']\n",
    "        retrieval_score = cos_scores[best_match_idx].item()\n",
    "        \n",
    "        # Choose final intent based on confidence\n",
    "        if cnn_confidence > 0.90:\n",
    "            final_intent = cnn_intent\n",
    "            source = \"CNN\"\n",
    "        else:\n",
    "            final_intent = retrieval_intent\n",
    "            source = \"Retrieval\"\n",
    "    \n",
    "    # ==================== SPECIAL CASES ====================\n",
    "        \n",
    "    # ==================== RESPONSE GENERATION ====================\n",
    "    response = RESPONSES.get(final_intent, RESPONSES.get(\"help\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    # Handle both dict (bilingual) and string responses\n",
    "    if isinstance(response, dict):\n",
    "        return response.get(\"en\", response.get(\"id\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"‚úì Chat function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9477ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß™ TESTING INFERENCE\n",
      "================================================================================\n",
      "\n",
      "Running test queries:\n",
      "\n",
      "üë§ User: hello\n",
      "ü§ñ Bot: Hello! üëã Welcome to Chattea.\n",
      "\n",
      "I'm here to help you navigate features like sending messages, managing...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: what is chattea\n",
      "ü§ñ Bot: Chattea is a WhatsApp marketing automation platform designed for businesses.\n",
      "\n",
      "üéØ Key features:\n",
      "‚Ä¢ Send...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: how to blast message\n",
      "ü§ñ Bot: To send a message:\n",
      "\n",
      "1. Choose an active instance\n",
      "2. Enter the destination number (e.g., 628123456789...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: check 08123456789\n",
      "ü§ñ Bot: To filter/check phone numbers:\n",
      "\n",
      "1. Open **Tools** ‚Üí **Phone Checker**\n",
      "2. Enter a phone number or upl...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: create instance\n",
      "ü§ñ Bot: To create a new WhatsApp instance:\n",
      "\n",
      "1. Open the **Instances** tab\n",
      "2. Click **+ New Instance**\n",
      "3. Ent...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: schedule message\n",
      "ü§ñ Bot: To schedule a message:\n",
      "\n",
      "1. Compose your message normally\n",
      "2. Click the **Schedule (‚è∞)** button\n",
      "3. Sel...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: thanks\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: goodbye\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 11: TEST INFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß™ TESTING INFERENCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_queries = [\n",
    "    \"hello\",\n",
    "    \"what is chattea\",\n",
    "    \"how to blast message\",\n",
    "    \"check 08123456789\",\n",
    "    \"create instance\",\n",
    "    \"schedule message\",\n",
    "    \"thanks\",\n",
    "    \"goodbye\"\n",
    "]\n",
    "\n",
    "print(\"\\nRunning test queries:\\n\")\n",
    "for query in test_queries:\n",
    "    print(f\"üë§ User: {query}\")\n",
    "    response = get_chattea_reply(query)\n",
    "    print(f\"ü§ñ Bot: {response[:100]}{'...' if len(response) > 100 else ''}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90d9f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä MODEL EVALUATION\n",
      "================================================================================\n",
      "‚úì Validation Accuracy: 0.1876 (18.76%)\n",
      "\n",
      "üìã Per-Intent Performance:\n",
      "   contact                       : 0.875 (32 samples)\n",
      "   create_group                  : 0.031 (32 samples)\n",
      "   create_instance               : 0.188 (32 samples)\n",
      "   delete_group                  : 0.156 (32 samples)\n",
      "   delete_instance               : 0.594 (32 samples)\n",
      "   edit_group                    : 0.062 (32 samples)\n",
      "   edit_instance                 : 0.031 (32 samples)\n",
      "   filter_number                 : 0.000 (32 samples)\n",
      "   greeting                      : 0.000 (13 samples)\n",
      "   pricing                       : 0.219 (32 samples)\n",
      "   schedule_message              : 0.000 (32 samples)\n",
      "   send_message                  : 0.000 (32 samples)\n",
      "   unknown                       : 0.000 (24 samples)\n",
      "   what_for                      : 0.312 (32 samples)\n",
      "Accuracy on FULL training set: 0.2050\n",
      "\n",
      "================================================================================\n",
      "‚úÖ NOTEBOOK COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Your model is ready to use!\n",
      "‚úì Deleted old model\n",
      "‚úì Cleared GPU cache\n",
      "\n",
      "‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 13: CNN MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä MODEL EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluate on validation set\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    X_all = embedder.encode(df['text'].tolist(), convert_to_tensor=True).to(device)\n",
    "    y_all = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        torch.arange(len(X_all)),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_all.cpu()\n",
    "    )\n",
    "    \n",
    "    X_val = X_all[val_idx].to(device)\n",
    "    y_val = y_all[val_idx].to(device)\n",
    "    \n",
    "    # Predict\n",
    "    val_outputs = cnn_model(X_val)\n",
    "    val_preds = val_outputs.argmax(1)\n",
    "    \n",
    "    # Accuracy\n",
    "    val_acc = (val_preds == y_val).float().mean().item()\n",
    "    \n",
    "    print(f\"‚úì Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nüìã Per-Intent Performance:\")\n",
    "    for intent_id in range(num_classes):\n",
    "        intent_name = intent_map[intent_id]\n",
    "        mask = y_val == intent_id\n",
    "        if mask.sum() > 0:\n",
    "            intent_acc = (val_preds[mask] == y_val[mask]).float().mean().item()\n",
    "            count = mask.sum().item()\n",
    "            print(f\"   {intent_name:30s}: {intent_acc:.3f} ({count:2d} samples)\")\n",
    "\n",
    "# Test on ALL training data (should be near perfect)\n",
    "with torch.no_grad():\n",
    "    all_outputs = cnn_model(sentence_embeddings.to(device))\n",
    "    all_preds = all_outputs.argmax(1)\n",
    "    all_labels = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    train_acc = (all_preds == all_labels).float().mean().item()\n",
    "    print(f\"Accuracy on FULL training set: {train_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ NOTEBOOK COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nYour model is ready to use!\")\n",
    "\n",
    "# ============================================================================\n",
    "# FRESH START - DELETE EVERYTHING AND RETRAIN\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. Delete saved model\n",
    "if os.path.exists(\"cnn_chattea.pth\"):\n",
    "    os.remove(\"cnn_chattea.pth\")\n",
    "    print(\"‚úì Deleted old model\")\n",
    "\n",
    "# 2. Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "# 3. Restart notebook kernel (Kernel ‚Üí Restart & Run All)\n",
    "print(\"\\n‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
