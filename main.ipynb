{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d62ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicho\\Documents\\GitHub_Repository\\Python\\chattea-ai\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHATTEA INTENT CLASSIFIER - MLP + SENTENCE TRANSFORMERS\n",
      "================================================================================\n",
      "PyTorch Version: 2.9.1+cu130\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Chattea Intent Classifier - MLP + Sentence Transformers\n",
    "# Complete Working Pipeline in Notebook Format\n",
    "# Ready to run cell by cell!\n",
    "\n",
    "\"\"\"\n",
    "JUPYTER NOTEBOOK STRUCTURE:\n",
    "Run each cell in order (Shift+Enter)\n",
    "\n",
    "Required Files:\n",
    "- chatbot_dataset.csv (text, intent columns)\n",
    "- responses.json (your bilingual responses)\n",
    "\n",
    "Installation:\n",
    "!pip install torch sentence-transformers scikit-learn pandas difflib\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from difflib import get_close_matches\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CHATTEA INTENT CLASSIFIER - MLP + SENTENCE TRANSFORMERS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1978fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Using device: cuda\n",
      "üéÆ GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "üíæ GPU Memory: 8.59 GB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: DEVICE CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - training will use CPU (slower)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7b133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìÇ LOADING DATA\n",
      "================================================================================\n",
      "‚úì Loaded dataset: 2102 samples\n",
      "‚úì Columns: ['text', 'intent']\n",
      "‚úì Unique intents: 14\n",
      "\n",
      "üìä Sample data:\n",
      "                                              text        intent\n",
      "0                          how do i send a message  send_message\n",
      "1            can you send a message to my contacts  send_message\n",
      "2                    i want to send a bulk message  send_message\n",
      "3                                     send message  send_message\n",
      "4                                 how to broadcast  send_message\n",
      "5      i need to send a message to multiple people  send_message\n",
      "6                          can i send messages now  send_message\n",
      "7                          send a whatsapp message  send_message\n",
      "8  how do i send bulk messages to my customer list  send_message\n",
      "9                i want to message all my contacts  send_message\n",
      "\n",
      "üìà Intent distribution:\n",
      "intent\n",
      "send_message        160\n",
      "schedule_message    160\n",
      "filter_number       160\n",
      "what_for            160\n",
      "pricing             160\n",
      "create_instance     159\n",
      "edit_instance       159\n",
      "delete_instance     159\n",
      "edit_group          159\n",
      "create_group        159\n",
      "delete_group        159\n",
      "contact             159\n",
      "unknown             124\n",
      "greeting             65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Loaded responses for 14 intents\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìÇ LOADING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load training dataset\n",
    "df = pd.read_csv(\"chatbot_dataset.csv\")\n",
    "print(f\"‚úì Loaded dataset: {len(df)} samples\")\n",
    "print(f\"‚úì Columns: {list(df.columns)}\")\n",
    "print(f\"‚úì Unique intents: {df['intent'].nunique()}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìä Sample data:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Intent distribution\n",
    "print(\"\\nüìà Intent distribution:\")\n",
    "intent_counts = df['intent'].value_counts()\n",
    "print(intent_counts.head(15))\n",
    "\n",
    "# Load responses\n",
    "with open(\"responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    RESPONSES = json.load(f)\n",
    "print(f\"\\n‚úì Loaded responses for {len(RESPONSES)} intents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76954e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìö BUILDING VOCABULARY FOR FUZZY MATCHING\n",
      "================================================================================\n",
      "‚úì Vocabulary size: 1037 unique words\n",
      "‚úì Sample words: ['offer', 'paying', 'bonjour', 'every', 'fresh', 'without', 'paid', 'anymore', 'hasn', 'recognize', 'were', 'thursday', 'reflect', 'lol', 'when', 'creating', 'follow', '1000', 'starting', 'does']\n",
      "\n",
      "üß™ Testing Fuzzy Correction:\n",
      "   'blst mesage' ‚Üí 'blast message'\n",
      "   'chek number' ‚Üí 'check number'\n",
      "   'craete instance' ‚Üí 'create instance'\n",
      "   'shedule mesage' ‚Üí 'schedule message'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: BUILD VOCABULARY FOR FUZZY MATCHING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö BUILDING VOCABULARY FOR FUZZY MATCHING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Extract all unique words from training data for typo correction\n",
    "all_words = set()\n",
    "for text in df['text'].str.lower():\n",
    "    all_words.update(re.findall(r'\\w+', text))\n",
    "\n",
    "VOCAB = all_words\n",
    "print(f\"‚úì Vocabulary size: {len(VOCAB)} unique words\")\n",
    "print(f\"‚úì Sample words: {list(VOCAB)[:20]}\")\n",
    "\n",
    "def fuzzy_correct(text: str, cutoff: float = 0.8) -> str:\n",
    "    \"\"\"\n",
    "    Typo correction using difflib (Fuzzy String Matching)\n",
    "    \n",
    "    Algorithm: Levenshtein Distance\n",
    "    - Finds closest matching words from vocabulary\n",
    "    - Corrects typos while preserving sentence structure\n",
    "    \n",
    "    Example: \"blst mesage\" ‚Üí \"blast message\"\n",
    "    \"\"\"\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    corrected = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Find closest match in vocabulary\n",
    "        matches = get_close_matches(word, VOCAB, n=1, cutoff=cutoff)\n",
    "        corrected.append(matches[0] if matches else word)\n",
    "    \n",
    "    # Reconstruct sentence preserving original punctuation\n",
    "    result = text\n",
    "    for orig, corr in zip(words, corrected):\n",
    "        if orig != corr:\n",
    "            result = re.sub(rf'\\b{orig}\\b', corr, result, count=1, flags=re.IGNORECASE)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test fuzzy correction\n",
    "print(\"\\nüß™ Testing Fuzzy Correction:\")\n",
    "test_cases = [\n",
    "    \"blst mesage\",\n",
    "    \"chek number\",\n",
    "    \"craete instance\",\n",
    "    \"shedule mesage\"\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    corrected = fuzzy_correct(test)\n",
    "    print(f\"   '{test}' ‚Üí '{corrected}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117afb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üè∑Ô∏è  ENCODING LABELS\n",
      "================================================================================\n",
      "‚úì Number of classes: 14\n",
      "\n",
      "üìã Intent mapping (first 10):\n",
      "   0: contact\n",
      "   1: create_group\n",
      "   2: create_instance\n",
      "   3: delete_group\n",
      "   4: delete_instance\n",
      "   5: edit_group\n",
      "   6: edit_instance\n",
      "   7: filter_number\n",
      "   8: greeting\n",
      "   9: pricing\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: LABEL ENCODING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üè∑Ô∏è  ENCODING LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Encode intent labels to numeric values\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['intent'])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "intent_map = dict(enumerate(le.classes_))\n",
    "\n",
    "print(f\"‚úì Number of classes: {num_classes}\")\n",
    "print(f\"\\nüìã Intent mapping (first 10):\")\n",
    "for idx, intent in list(intent_map.items())[:10]:\n",
    "    print(f\"   {idx}: {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cea0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß† GENERATING SENTENCE EMBEDDINGS\n",
      "================================================================================\n",
      "Using: Sentence Transformers (all-MiniLM-L6-v2)\n",
      "This is a neural embedding model (similar to Word2Vec but sentence-level)\n",
      "================================================================================\n",
      "‚úì Loaded embedding model\n",
      "‚úì Embedding dimension: 384\n",
      "\n",
      "üìä Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:01<00:00, 53.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generated embeddings: torch.Size([2102, 384])\n",
      "   - Shape: (num_samples, embedding_dim)\n",
      "   - Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 6: SENTENCE EMBEDDINGS (WORD2VEC ALTERNATIVE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß† GENERATING SENTENCE EMBEDDINGS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Using: Sentence Transformers (all-MiniLM-L6-v2)\")\n",
    "print(\"This is a neural embedding model (similar to Word2Vec but sentence-level)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load pre-trained sentence embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"‚úì Loaded embedding model\")\n",
    "print(f\"‚úì Embedding dimension: 384\")\n",
    "\n",
    "# Generate embeddings for all training samples\n",
    "print(\"\\nüìä Encoding training data...\")\n",
    "sentence_embeddings = embedder.encode(\n",
    "    df['text'].tolist(), \n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True\n",
    ").to(device)\n",
    "\n",
    "print(f\"‚úì Generated embeddings: {sentence_embeddings.shape}\")\n",
    "print(f\"   - Shape: (num_samples, embedding_dim)\")\n",
    "print(f\"   - Device: {sentence_embeddings.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c65f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèóÔ∏è  FEEDFORWARD CLASSIFIER ARCHITECTURE\n",
      "================================================================================\n",
      "\n",
      "üìê Model Architecture:\n",
      "EmbeddingClassifier(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=14, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "‚úì Total parameters: 133,262\n",
      "‚úì Model defined successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 7: FEEDFORWARD NETWORK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèóÔ∏è  FEEDFORWARD CLASSIFIER ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple Feedforward Neural Network for Sentence Embeddings\n",
    "    \n",
    "    Why not CNN?\n",
    "    - CNNs are for sequential data (words in sentence)\n",
    "    - We already have holistic sentence embeddings (384-dim vectors)\n",
    "    - Feedforward network is the right architecture for this!\n",
    "    \n",
    "    Architecture:\n",
    "    1. Input: 384-dim sentence embedding\n",
    "    2. Hidden Layer 1: 384 ‚Üí 256 (ReLU + Dropout)\n",
    "    3. Hidden Layer 2: 256 ‚Üí 128 (ReLU + Dropout)\n",
    "    4. Output Layer: 128 ‚Üí num_classes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim=384, num_classes=num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Linear(embed_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 384)\n",
    "        return self.network(x)  # (batch_size, num_classes)\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nüìê Model Architecture:\")\n",
    "model = EmbeddingClassifier()\n",
    "print(model)\n",
    "print(f\"\\n‚úì Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\"‚úì Model defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479cfcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ TRAINING MLP MODEL\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìö PREPARING TRAINING DATA\n",
      "================================================================================\n",
      "‚úì X shape: torch.Size([2102, 384])\n",
      "‚úì y shape: torch.Size([2102])\n",
      "\n",
      "‚úì Training samples: 1681\n",
      "‚úì Validation samples: 421\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è  TRAINING LOOP (WITH PROPER BATCHING!)\n",
      "================================================================================\n",
      "\n",
      "Epoch | Train Acc | Train Loss | Val Acc | Val Loss\n",
      "-----------------------------------------------------------------\n",
      "    0 |    0.4878 |     2.3190 |  0.8741 |   1.4435\n",
      "    5 |    0.9780 |     0.0710 |  0.9857 |   0.0426\n",
      "   10 |    0.9958 |     0.0262 |  0.9905 |   0.0232\n",
      "   15 |    0.9976 |     0.0130 |  0.9952 |   0.0222\n",
      "   20 |    0.9994 |     0.0086 |  0.9952 |   0.0194\n",
      "   25 |    0.9988 |     0.0054 |  0.9952 |   0.0164\n",
      "   30 |    1.0000 |     0.0030 |  0.9952 |   0.0191\n",
      "   35 |    0.9988 |     0.0039 |  0.9929 |   0.0191\n",
      "   40 |    0.9994 |     0.0026 |  0.9952 |   0.0178\n",
      "   45 |    1.0000 |     0.0022 |  0.9952 |   0.0182\n",
      "   49 |    0.9994 |     0.0018 |  0.9952 |   0.0183\n",
      "\n",
      "================================================================================\n",
      "‚úì Training Complete!\n",
      "‚úì Best Validation Accuracy: 0.9952 (99.52%)\n",
      "‚úì Model saved to: chattea.pth\n",
      "================================================================================\n",
      "\n",
      "üìä Final Performance:\n",
      "   Training Accuracy:   0.9988 (99.88%)\n",
      "   Validation Accuracy: 0.9952 (99.52%)\n",
      "\n",
      "‚úì Model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 8: TRAIN OR LOAD MLP MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ TRAINING MLP MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_path = \"chattea.pth\"\n",
    "\n",
    "# Force retrain\n",
    "import os\n",
    "if os.path.exists(model_path):\n",
    "    os.remove(model_path)\n",
    "    print(\"‚ö†Ô∏è  Deleted old model - retraining from scratch!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö PREPARING TRAINING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use the pre-computed embeddings from Cell 6\n",
    "X = sentence_embeddings.to(device)\n",
    "y = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "\n",
    "print(f\"‚úì X shape: {X.shape}\")\n",
    "print(f\"‚úì y shape: {y.shape}\")\n",
    "\n",
    "# Train/validation split (stratified)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    list(range(len(X))),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y.cpu()\n",
    ")\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_val = X[val_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "print(f\"\\n‚úì Training samples: {len(X_train)}\")\n",
    "print(f\"‚úì Validation samples: {len(X_val)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèãÔ∏è  TRAINING LOOP (WITH PROPER BATCHING!)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize model\n",
    "model = EmbeddingClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Lower LR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50  # More epochs\n",
    "\n",
    "# Create mini-batches\n",
    "def create_batches(X, y, batch_size):\n",
    "    \"\"\"Create mini-batches for training\"\"\"\n",
    "    indices = torch.randperm(len(X))\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        batch_idx = indices[i:i+batch_size]\n",
    "        yield X[batch_idx], y[batch_idx]\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nEpoch | Train Acc | Train Loss | Val Acc | Val Loss\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ========== TRAINING ==========\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_X, batch_y in create_batches(X_train, y_train, BATCH_SIZE):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (outputs.argmax(1) == batch_y).sum().item()\n",
    "        train_total += len(batch_y)\n",
    "    \n",
    "    train_acc = train_correct / train_total\n",
    "    train_loss = train_loss / (len(X_train) // BATCH_SIZE + 1)\n",
    "    \n",
    "    # ========== VALIDATION ==========\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val).item()\n",
    "        val_acc = (val_outputs.argmax(1) == y_val).float().mean().item()\n",
    "    \n",
    "    # Print progress\n",
    "    if epoch % 5 == 0 or epoch == EPOCHS - 1:\n",
    "        print(f\"{epoch:5d} | {train_acc:9.4f} | {train_loss:10.4f} | {val_acc:7.4f} | {val_loss:8.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úì Training Complete!\")\n",
    "print(f\"‚úì Best Validation Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "print(f\"‚úì Model saved to: {model_path}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Final check on training data\n",
    "with torch.no_grad():\n",
    "    final_train_pred = model(X_train).argmax(1)\n",
    "    final_train_acc = (final_train_pred == y_train).float().mean().item()\n",
    "    \n",
    "    final_val_pred = model(X_val).argmax(1)\n",
    "    final_val_acc = (final_val_pred == y_val).float().mean().item()\n",
    "\n",
    "print(f\"\\nüìä Final Performance:\")\n",
    "print(f\"   Training Accuracy:   {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "print(f\"   Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úì Model ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aadc9d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üí¨ CHAT INFERENCE FUNCTION\n",
      "================================================================================\n",
      "‚úì Chat function ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: MAIN CHAT FUNCTION (INFERENCE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí¨ CHAT INFERENCE FUNCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def get_chattea_reply(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Main chatbot inference function\n",
    "    \n",
    "    Pipeline:\n",
    "    1. Rule-based filters (greetings, goodbyes)\n",
    "    2. Phone number extraction (if applicable)\n",
    "    3. CNN classification with confidence check\n",
    "    4. Retrieval fallback (if low confidence)\n",
    "    5. Response generation\n",
    "    \n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        \n",
    "    Returns:\n",
    "        Bot's response\n",
    "    \"\"\"\n",
    "    text = user_input.strip().lower()\n",
    "    \n",
    "    # ==================== RULE-BASED FILTERS ====================\n",
    "    # Quick responses for common greetings\n",
    "    if any(g in text for g in [\"hai\", \"halo\", \"hello\", \"hi\", \"hey\", \"pagi\", \"siang\", \"malam\"]):\n",
    "        return RESPONSES[\"greeting\"][\"en\"]\n",
    "    \n",
    "    if any(g in text for g in [\"bye\", \"goodbye\", \"dadah\", \"sampai jumpa\"]):\n",
    "        return RESPONSES[\"unknown\"][\"en\"]\n",
    "    \n",
    "    # ==================== EMBEDDING + PREDICTION ====================\n",
    "    with torch.no_grad():\n",
    "        # Encode user input\n",
    "        user_emb = embedder.encode(user_input, convert_to_tensor=True).to(device)\n",
    "        user_emb = user_emb.unsqueeze(0)  # (1, 384)\n",
    "        \n",
    "        # MLP prediction\n",
    "        logits = model(user_emb)\n",
    "        probs = logits.softmax(1)\n",
    "        confidence = probs.max().item()\n",
    "        intent = intent_map[logits.argmax(1).item()]\n",
    "        \n",
    "        # Retrieval fallback (semantic similarity)\n",
    "        cos_scores = util.cos_sim(user_emb, sentence_embeddings)[0]\n",
    "        best_match_idx = cos_scores.argmax().item()\n",
    "        retrieval_intent = df.iloc[best_match_idx]['intent']\n",
    "        retrieval_score = cos_scores[best_match_idx].item()\n",
    "        \n",
    "        # Choose final intent based on confidence\n",
    "        if confidence > 0.90:\n",
    "            final_intent = intent\n",
    "            source = \"MLP\"\n",
    "        else:\n",
    "            final_intent = retrieval_intent\n",
    "            source = \"Retrieval\"\n",
    "    \n",
    "    # ==================== SPECIAL CASES ====================\n",
    "\n",
    "    # ==================== RESPONSE GENERATION ====================\n",
    "    response = RESPONSES.get(final_intent, RESPONSES.get(\"help\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    # Handle both dict (bilingual) and string responses\n",
    "    if isinstance(response, dict):\n",
    "        return response.get(\"en\", response.get(\"id\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"‚úì Chat function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0fbf495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß™ TESTING INFERENCE\n",
      "================================================================================\n",
      "\n",
      "Running test queries:\n",
      "\n",
      "üë§ User: hello\n",
      "ü§ñ Bot: Hello! üëã Welcome to Chattea.\n",
      "\n",
      "I'm here to help you navigate features like sending messages, managing...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: what is chattea\n",
      "ü§ñ Bot: Chattea is a WhatsApp marketing automation platform designed for businesses.\n",
      "\n",
      "üéØ Key features:\n",
      "‚Ä¢ Send...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: how to blast message\n",
      "ü§ñ Bot: To send a message:\n",
      "\n",
      "1. Choose an active instance\n",
      "2. Enter the destination number (e.g., 628123456789...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: check 08123456789\n",
      "ü§ñ Bot: To filter/check phone numbers:\n",
      "\n",
      "1. Open **Tools** ‚Üí **Phone Checker**\n",
      "2. Enter a phone number or upl...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: create instance\n",
      "ü§ñ Bot: To create a new WhatsApp instance:\n",
      "\n",
      "1. Open the **Instances** tab\n",
      "2. Click **+ New Instance**\n",
      "3. Ent...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: schedule message\n",
      "ü§ñ Bot: To schedule a message:\n",
      "\n",
      "1. Compose your message normally\n",
      "2. Click the **Schedule (‚è∞)** button\n",
      "3. Sel...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: thanks\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: goodbye\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 11: TEST INFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß™ TESTING INFERENCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_queries = [\n",
    "    \"hello\",\n",
    "    \"what is chattea\",\n",
    "    \"how to blast message\",\n",
    "    \"check 08123456789\",\n",
    "    \"create instance\",\n",
    "    \"schedule message\",\n",
    "    \"thanks\",\n",
    "    \"goodbye\"\n",
    "]\n",
    "\n",
    "print(\"\\nRunning test queries:\\n\")\n",
    "for query in test_queries:\n",
    "    print(f\"üë§ User: {query}\")\n",
    "    response = get_chattea_reply(query)\n",
    "    print(f\"ü§ñ Bot: {response[:100]}{'...' if len(response) > 100 else ''}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc463ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä MODEL EVALUATION\n",
      "================================================================================\n",
      "‚úì Validation Accuracy: 0.9952 (99.52%)\n",
      "\n",
      "üìã Per-Intent Performance:\n",
      "   contact                       : 1.000 (32 samples)\n",
      "   create_group                  : 1.000 (32 samples)\n",
      "   create_instance               : 1.000 (32 samples)\n",
      "   delete_group                  : 1.000 (32 samples)\n",
      "   delete_instance               : 1.000 (32 samples)\n",
      "   edit_group                    : 1.000 (32 samples)\n",
      "   edit_instance                 : 1.000 (32 samples)\n",
      "   filter_number                 : 1.000 (32 samples)\n",
      "   greeting                      : 0.923 (13 samples)\n",
      "   pricing                       : 1.000 (32 samples)\n",
      "   schedule_message              : 1.000 (32 samples)\n",
      "   send_message                  : 1.000 (32 samples)\n",
      "   unknown                       : 1.000 (24 samples)\n",
      "   what_for                      : 0.969 (32 samples)\n",
      "Accuracy on FULL training set: 0.9981\n",
      "\n",
      "================================================================================\n",
      "‚úÖ NOTEBOOK COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Your model is ready to use!\n",
      "‚úì Deleted old model\n",
      "‚úì Cleared GPU cache\n",
      "\n",
      "‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 13: MLP MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä MODEL EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluate on validation set\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    X_all = embedder.encode(df['text'].tolist(), convert_to_tensor=True).to(device)\n",
    "    y_all = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        torch.arange(len(X_all)),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_all.cpu()\n",
    "    )\n",
    "    \n",
    "    X_val = X_all[val_idx].to(device)\n",
    "    y_val = y_all[val_idx].to(device)\n",
    "    \n",
    "    # Predict\n",
    "    val_outputs = model(X_val)\n",
    "    val_preds = val_outputs.argmax(1)\n",
    "    \n",
    "    # Accuracy\n",
    "    val_acc = (val_preds == y_val).float().mean().item()\n",
    "    \n",
    "    print(f\"‚úì Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nüìã Per-Intent Performance:\")\n",
    "    for intent_id in range(num_classes):\n",
    "        intent_name = intent_map[intent_id]\n",
    "        mask = y_val == intent_id\n",
    "        if mask.sum() > 0:\n",
    "            intent_acc = (val_preds[mask] == y_val[mask]).float().mean().item()\n",
    "            count = mask.sum().item()\n",
    "            print(f\"   {intent_name:30s}: {intent_acc:.3f} ({count:2d} samples)\")\n",
    "\n",
    "# Test on ALL training data (should be near perfect)\n",
    "with torch.no_grad():\n",
    "    all_outputs = model(sentence_embeddings.to(device))\n",
    "    all_preds = all_outputs.argmax(1)\n",
    "    all_labels = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    train_acc = (all_preds == all_labels).float().mean().item()\n",
    "    print(f\"Accuracy on FULL training set: {train_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ NOTEBOOK COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nYour model is ready to use!\")\n",
    "\n",
    "# ============================================================================\n",
    "# FRESH START - DELETE EVERYTHING AND RETRAIN\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. Delete saved model\n",
    "if os.path.exists(\"chattea.pth\"):\n",
    "    os.remove(\"chattea.pth\")\n",
    "    print(\"‚úì Deleted old model\")\n",
    "\n",
    "# 2. Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "# 3. Restart notebook kernel (Kernel ‚Üí Restart & Run All)\n",
    "print(\"\\n‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d3cfee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèóÔ∏è  CNN MODEL ARCHITECTURE\n",
      "================================================================================\n",
      "\n",
      "üìê Model Architecture:\n",
      "TextCNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv1d(1, 128, kernel_size=(3,), stride=(1,))\n",
      "    (1): Conv1d(1, 128, kernel_size=(4,), stride=(1,))\n",
      "    (2): Conv1d(1, 128, kernel_size=(5,), stride=(1,))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=384, out_features=14, bias=True)\n",
      ")\n",
      "\n",
      "‚úì Model defined successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 7: CNN MODEL ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèóÔ∏è  CNN MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for Text Classification\n",
    "    \n",
    "    Architecture:\n",
    "    1. Input: Sentence embeddings (384-dim vectors)\n",
    "    2. Multiple Conv1D layers with different kernel sizes (3, 4, 5)\n",
    "       - Detects patterns of different n-gram lengths\n",
    "    3. Max pooling: Extract most important features\n",
    "    4. Dropout: Prevent overfitting (40%)\n",
    "    5. Fully connected layer: Final classification\n",
    "    \n",
    "    Why CNN for text?\n",
    "    - Detects local patterns (like phrases)\n",
    "    - Translation invariant (same pattern anywhere in text)\n",
    "    - Faster than RNN/LSTM\n",
    "    - Simpler than Transformers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim=384, num_classes=num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multiple convolution layers with different kernel sizes\n",
    "        # This captures n-grams of different lengths\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=1, out_channels=128, kernel_size=k) \n",
    "            for k in [3, 4, 5]\n",
    "        ])\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(128 * 3, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 384)\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, 384)\n",
    "        \n",
    "        # Apply convolutions and max pooling\n",
    "        convs = [F.relu(conv(x)).max(dim=2)[0] for conv in self.convs]\n",
    "        \n",
    "        # Concatenate all conv outputs\n",
    "        x = torch.cat(convs, dim=1)  # (batch_size, 128*3)\n",
    "        \n",
    "        # Dropout and classification\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nüìê Model Architecture:\")\n",
    "print(TextCNN())\n",
    "print(\"\\n‚úì Model defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe6bbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ TRAINING CNN MODEL\n",
      "================================================================================\n",
      "‚ö†Ô∏è  No pre-trained model found. Training from scratch...\n",
      "\n",
      "================================================================================\n",
      "üìö PREPARING TRAINING DATA\n",
      "================================================================================\n",
      "‚úì X shape: torch.Size([2102, 384])\n",
      "‚úì y shape: torch.Size([2102])\n",
      "\n",
      "‚úì Training samples: 1681\n",
      "‚úì Validation samples: 421\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è  TRAINING LOOP\n",
      "================================================================================\n",
      "\n",
      "Epoch | Accuracy | Loss\n",
      "----------------------------------------\n",
      "    0 |   0.0714 |   2.6593\n",
      "    5 |   0.0833 |   2.6337\n",
      "   10 |   0.0756 |   2.6298\n",
      "   15 |   0.0892 |   2.6273\n",
      "   20 |   0.0821 |   2.6222\n",
      "   25 |   0.0964 |   2.6161\n",
      "\n",
      "================================================================================\n",
      "‚úì Final Training Accuracy: 0.0976 (9.76%)\n",
      "‚úì Final Validation Accuracy: 0.0998 (9.98%)\n",
      "================================================================================\n",
      "\n",
      "‚úì Model saved to: cnn_chattea.pth\n",
      "\n",
      "‚úì Model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 8: TRAIN OR LOAD CNN MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ TRAINING CNN MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_path = \"cnn_chattea.pth\"\n",
    "\n",
    "try:\n",
    "    # Try to load pre-trained model\n",
    "    cnn_model = TextCNN().to(device)\n",
    "    cnn_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(\"‚úì Loaded pre-trained CNN model from\", model_path)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è  No pre-trained model found. Training from scratch...\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìö PREPARING TRAINING DATA\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Encode all texts\n",
    "    X = embedder.encode(df['text'].tolist(), convert_to_tensor=True).to(device)\n",
    "    y = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    print(f\"‚úì X shape: {X.shape}\")\n",
    "    print(f\"‚úì y shape: {y.shape}\")\n",
    "    \n",
    "    # Train/validation split (stratified)\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        torch.arange(len(X)),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y.cpu()  # Stratify to maintain class distribution\n",
    "    )\n",
    "    \n",
    "    X_train = X[train_idx].to(device)\n",
    "    X_val = X[val_idx].to(device)\n",
    "    y_train = y[train_idx].to(device)\n",
    "    y_val = y[val_idx].to(device)\n",
    "    \n",
    "    print(f\"\\n‚úì Training samples: {len(X_train)}\")\n",
    "    print(f\"‚úì Validation samples: {len(X_val)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üèãÔ∏è  TRAINING LOOP\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Initialize model\n",
    "    cnn_model = TextCNN().to(device)\n",
    "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.002)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    cnn_model.train()\n",
    "    print(\"\\nEpoch | Accuracy | Loss\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for epoch in range(30):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = cnn_model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = (outputs.argmax(1) == y_train).float().mean().item()\n",
    "        \n",
    "        # Print progress every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"{epoch:5d} | {acc:8.4f} | {loss.item():8.4f}\")\n",
    "    \n",
    "    # Final training accuracy\n",
    "    with torch.no_grad():\n",
    "        outputs = cnn_model(X_train)\n",
    "        train_acc = (outputs.argmax(1) == y_train).float().mean().item()\n",
    "        \n",
    "        # Validation accuracy\n",
    "        val_outputs = cnn_model(X_val)\n",
    "        val_acc = (val_outputs.argmax(1) == y_val).float().mean().item()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"‚úì Final Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "    print(f\"‚úì Final Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(cnn_model.state_dict(), model_path)\n",
    "    print(f\"\\n‚úì Model saved to: {model_path}\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "cnn_model.eval()\n",
    "print(\"\\n‚úì Model ready for inference!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d8b4ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üí¨ CHAT INFERENCE FUNCTION\n",
      "================================================================================\n",
      "‚úì Chat function ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: MAIN CHAT FUNCTION (INFERENCE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí¨ CHAT INFERENCE FUNCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def get_chattea_reply(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Main chatbot inference function\n",
    "    \n",
    "    Pipeline:\n",
    "    1. Rule-based filters (greetings, goodbyes)\n",
    "    2. Phone number extraction (if applicable)\n",
    "    3. CNN classification with confidence check\n",
    "    4. Retrieval fallback (if low confidence)\n",
    "    5. Response generation\n",
    "    \n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        \n",
    "    Returns:\n",
    "        Bot's response\n",
    "    \"\"\"\n",
    "    text = user_input.strip().lower()\n",
    "    \n",
    "    # ==================== RULE-BASED FILTERS ====================\n",
    "    # Quick responses for common greetings\n",
    "    if any(g in text for g in [\"hai\", \"halo\", \"hello\", \"hi\", \"hey\", \"pagi\", \"siang\", \"malam\"]):\n",
    "        return RESPONSES[\"greeting\"][\"en\"]\n",
    "    \n",
    "    if any(g in text for g in [\"bye\", \"goodbye\", \"dadah\", \"sampai jumpa\"]):\n",
    "        return RESPONSES[\"unknown\"][\"en\"]\n",
    "    \n",
    "    # ==================== EMBEDDING + PREDICTION ====================\n",
    "    with torch.no_grad():\n",
    "        # Encode user input\n",
    "        user_emb = embedder.encode(user_input, convert_to_tensor=True).to(device)\n",
    "        user_emb = user_emb.unsqueeze(0)  # (1, 384)\n",
    "        \n",
    "        # CNN prediction\n",
    "        cnn_logits = cnn_model(user_emb)\n",
    "        cnn_probs = cnn_logits.softmax(1)\n",
    "        cnn_confidence = cnn_probs.max().item()\n",
    "        cnn_intent = intent_map[cnn_logits.argmax(1).item()]\n",
    "        \n",
    "        # Retrieval fallback (semantic similarity)\n",
    "        cos_scores = util.cos_sim(user_emb, sentence_embeddings)[0]\n",
    "        best_match_idx = cos_scores.argmax().item()\n",
    "        retrieval_intent = df.iloc[best_match_idx]['intent']\n",
    "        retrieval_score = cos_scores[best_match_idx].item()\n",
    "        \n",
    "        # Choose final intent based on confidence\n",
    "        if cnn_confidence > 0.90:\n",
    "            final_intent = cnn_intent\n",
    "            source = \"CNN\"\n",
    "        else:\n",
    "            final_intent = retrieval_intent\n",
    "            source = \"Retrieval\"\n",
    "    \n",
    "    # ==================== SPECIAL CASES ====================\n",
    "        \n",
    "    # ==================== RESPONSE GENERATION ====================\n",
    "    response = RESPONSES.get(final_intent, RESPONSES.get(\"help\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    # Handle both dict (bilingual) and string responses\n",
    "    if isinstance(response, dict):\n",
    "        return response.get(\"en\", response.get(\"id\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"‚úì Chat function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9477ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß™ TESTING INFERENCE\n",
      "================================================================================\n",
      "\n",
      "Running test queries:\n",
      "\n",
      "üë§ User: hello\n",
      "ü§ñ Bot: Hello! üëã Welcome to Chattea.\n",
      "\n",
      "I'm here to help you navigate features like sending messages, managing...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: what is chattea\n",
      "ü§ñ Bot: Chattea is a WhatsApp marketing automation platform designed for businesses.\n",
      "\n",
      "üéØ Key features:\n",
      "‚Ä¢ Send...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: how to blast message\n",
      "ü§ñ Bot: To send a message:\n",
      "\n",
      "1. Choose an active instance\n",
      "2. Enter the destination number (e.g., 628123456789...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: check 08123456789\n",
      "ü§ñ Bot: To filter/check phone numbers:\n",
      "\n",
      "1. Open **Tools** ‚Üí **Phone Checker**\n",
      "2. Enter a phone number or upl...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: create instance\n",
      "ü§ñ Bot: To create a new WhatsApp instance:\n",
      "\n",
      "1. Open the **Instances** tab\n",
      "2. Click **+ New Instance**\n",
      "3. Ent...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: schedule message\n",
      "ü§ñ Bot: To schedule a message:\n",
      "\n",
      "1. Compose your message normally\n",
      "2. Click the **Schedule (‚è∞)** button\n",
      "3. Sel...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: thanks\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: goodbye\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 11: TEST INFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß™ TESTING INFERENCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_queries = [\n",
    "    \"hello\",\n",
    "    \"what is chattea\",\n",
    "    \"how to blast message\",\n",
    "    \"check 08123456789\",\n",
    "    \"create instance\",\n",
    "    \"schedule message\",\n",
    "    \"thanks\",\n",
    "    \"goodbye\"\n",
    "]\n",
    "\n",
    "print(\"\\nRunning test queries:\\n\")\n",
    "for query in test_queries:\n",
    "    print(f\"üë§ User: {query}\")\n",
    "    response = get_chattea_reply(query)\n",
    "    print(f\"ü§ñ Bot: {response[:100]}{'...' if len(response) > 100 else ''}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90d9f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä MODEL EVALUATION\n",
      "================================================================================\n",
      "‚úì Validation Accuracy: 0.1758 (17.58%)\n",
      "\n",
      "üìã Per-Intent Performance:\n",
      "   contact                       : 0.094 (32 samples)\n",
      "   create_group                  : 0.531 (32 samples)\n",
      "   create_instance               : 0.000 (32 samples)\n",
      "   delete_group                  : 0.250 (32 samples)\n",
      "   delete_instance               : 0.094 (32 samples)\n",
      "   edit_group                    : 0.906 (32 samples)\n",
      "   edit_instance                 : 0.031 (32 samples)\n",
      "   filter_number                 : 0.000 (32 samples)\n",
      "   greeting                      : 0.000 (13 samples)\n",
      "   pricing                       : 0.406 (32 samples)\n",
      "   schedule_message              : 0.000 (32 samples)\n",
      "   send_message                  : 0.000 (32 samples)\n",
      "   unknown                       : 0.000 (24 samples)\n",
      "   what_for                      : 0.000 (32 samples)\n",
      "Accuracy on FULL training set: 0.1912\n",
      "\n",
      "================================================================================\n",
      "‚úÖ NOTEBOOK COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Your model is ready to use!\n",
      "‚úì Deleted old model\n",
      "‚úì Cleared GPU cache\n",
      "\n",
      "‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 13: CNN MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä MODEL EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluate on validation set\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    X_all = embedder.encode(df['text'].tolist(), convert_to_tensor=True).to(device)\n",
    "    y_all = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        torch.arange(len(X_all)),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_all.cpu()\n",
    "    )\n",
    "    \n",
    "    X_val = X_all[val_idx].to(device)\n",
    "    y_val = y_all[val_idx].to(device)\n",
    "    \n",
    "    # Predict\n",
    "    val_outputs = cnn_model(X_val)\n",
    "    val_preds = val_outputs.argmax(1)\n",
    "    \n",
    "    # Accuracy\n",
    "    val_acc = (val_preds == y_val).float().mean().item()\n",
    "    \n",
    "    print(f\"‚úì Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nüìã Per-Intent Performance:\")\n",
    "    for intent_id in range(num_classes):\n",
    "        intent_name = intent_map[intent_id]\n",
    "        mask = y_val == intent_id\n",
    "        if mask.sum() > 0:\n",
    "            intent_acc = (val_preds[mask] == y_val[mask]).float().mean().item()\n",
    "            count = mask.sum().item()\n",
    "            print(f\"   {intent_name:30s}: {intent_acc:.3f} ({count:2d} samples)\")\n",
    "\n",
    "# Test on ALL training data (should be near perfect)\n",
    "with torch.no_grad():\n",
    "    all_outputs = cnn_model(sentence_embeddings.to(device))\n",
    "    all_preds = all_outputs.argmax(1)\n",
    "    all_labels = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    train_acc = (all_preds == all_labels).float().mean().item()\n",
    "    print(f\"Accuracy on FULL training set: {train_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ NOTEBOOK COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nYour model is ready to use!\")\n",
    "\n",
    "# ============================================================================\n",
    "# FRESH START - DELETE EVERYTHING AND RETRAIN\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. Delete saved model\n",
    "if os.path.exists(\"cnn_chattea.pth\"):\n",
    "    os.remove(\"cnn_chattea.pth\")\n",
    "    print(\"‚úì Deleted old model\")\n",
    "\n",
    "# 2. Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "# 3. Restart notebook kernel (Kernel ‚Üí Restart & Run All)\n",
    "print(\"\\n‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64dc7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from difflib import get_close_matches, SequenceMatcher\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    # File paths\n",
    "    DATASET_PATH = \"chatbot_dataset.csv\"\n",
    "    RESPONSES_PATH = \"responses.json\"\n",
    "    MODEL_PATH = \"cnn_chattea.pth\"\n",
    "    WORD2VEC_PATH = \"word2vec.model\"\n",
    "    \n",
    "    # Word2Vec parameters\n",
    "    EMBEDDING_DIM = 100        # Embedding dimension\n",
    "    WORD2VEC_WINDOW = 5        # Context window\n",
    "    WORD2VEC_MIN_COUNT = 1     # Minimum word frequency\n",
    "    WORD2VEC_SG = 1            # Skip-gram (better for small datasets)\n",
    "\n",
    "    # CNN parameters\n",
    "    NUM_FILTERS = 128          # Filters per kernel\n",
    "    KERNEL_SIZES = [2, 3, 4]   # Includes 2-word phrases!\n",
    "    DROPOUT = 0.5              # Higher regularization\n",
    "    MAX_SEQ_LENGTH = 20        # Shorter = more efficient\n",
    "\n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 30\n",
    "    LEARNING_RATE = 0.001\n",
    "    TEST_SIZE = 0.2\n",
    "    RANDOM_SEED = 42\n",
    "\n",
    "    # Inference parameters\n",
    "    FUZZY_CUTOFF = 0.8\n",
    "    CONFIDENCE_THRESHOLD = 0.75\n",
    "\n",
    "    # Device\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(Config.RANDOM_SEED)\n",
    "np.random.seed(Config.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2216974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä DATASET SANITY CHECK & ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£  BASIC STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total samples: 2102\n",
      "Total intents: 14\n",
      "Columns: ['text', 'intent']\n",
      "\n",
      "2Ô∏è‚É£  DATA QUALITY\n",
      "--------------------------------------------------------------------------------\n",
      "Missing values:\n",
      "  text: 0 (0.00%)\n",
      "  intent: 0 (0.00%)\n",
      "\n",
      "Duplicate rows: 47 (2.24%)\n",
      "\n",
      "3Ô∏è‚É£  INTENT DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "intent\n",
      "send_message        160\n",
      "schedule_message    160\n",
      "filter_number       160\n",
      "what_for            160\n",
      "pricing             160\n",
      "create_instance     159\n",
      "edit_instance       159\n",
      "delete_instance     159\n",
      "edit_group          159\n",
      "create_group        159\n",
      "delete_group        159\n",
      "contact             159\n",
      "unknown             124\n",
      "greeting             65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Most common: send_message (160 samples)\n",
      "Least common: greeting (65 samples)\n",
      "Class imbalance ratio: 2.46x\n",
      "\n",
      "4Ô∏è‚É£  TEXT LENGTH ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Character length:\n",
      "  Min: 2\n",
      "  Max: 115\n",
      "  Mean: 38.17\n",
      "  Median: 34\n",
      "\n",
      "Word count:\n",
      "  Min: 1\n",
      "  Max: 21\n",
      "  Mean: 6.87\n",
      "  Median: 7\n",
      "\n",
      "5Ô∏è‚É£  LONGEST SENTENCES (Top 5)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[21 words] Intent: send_message\n",
      "Text: i want to send a promotional message to all my contacts in my database so they know about our upcoming sale\n",
      "\n",
      "[20 words] Intent: schedule_message\n",
      "Text: i'd like to schedule my promotional messages to go out at 10am tomorrow morning when most people check their phones\n",
      "\n",
      "[19 words] Intent: create_instance\n",
      "Text: i need to create a new whatsapp business instance for my online store so i can start messaging customers\n",
      "\n",
      "[19 words] Intent: create_group\n",
      "Text: i need to create a customer group for all my vip clients so i can send them exclusive offers\n",
      "\n",
      "[18 words] Intent: filter_number\n",
      "Text: i need to filter my contact list to remove all the invalid phone numbers before sending my campaign\n",
      "\n",
      "6Ô∏è‚É£  SHORTEST SENTENCES (Top 5)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1 words] Intent: pricing\n",
      "Text: pricing\n",
      "\n",
      "[1 words] Intent: contact\n",
      "Text: contact\n",
      "\n",
      "[1 words] Intent: greeting\n",
      "Text: hello\n",
      "\n",
      "[1 words] Intent: greeting\n",
      "Text: hi\n",
      "\n",
      "[1 words] Intent: greeting\n",
      "Text: hey\n",
      "\n",
      "7Ô∏è‚É£  VOCABULARY STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total words (with repetition): 14450\n",
      "Unique words: 1050\n",
      "Vocabulary richness: 0.0727\n",
      "\n",
      "Most common words (Top 10):\n",
      "  'to': 926 times\n",
      "  'i': 662 times\n",
      "  'can': 427 times\n",
      "  'how': 392 times\n",
      "  'instance': 355 times\n",
      "  'my': 328 times\n",
      "  'a': 309 times\n",
      "  'you': 301 times\n",
      "  'group': 290 times\n",
      "  'for': 282 times\n",
      "\n",
      "8Ô∏è‚É£  HYPERPARAMETER JUSTIFICATION\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì MAX_SEQ_LENGTH = 20\n",
      "  Rationale: 95th percentile = 13 words\n",
      "  Only 1 samples (0.05%) exceed this length\n",
      "\n",
      "‚úì EMBEDDING_DIM = 100\n",
      "  Rationale: Vocabulary size = 1050\n",
      "  Rule of thumb: embedding_dim ‚âà vocab_size^0.25 = 6\n",
      "  100 dimensions provides good balance for vocab of ~1000 words\n",
      "\n",
      "‚úì KERNEL_SIZES = [2, 3, 4]\n",
      "  Rationale: Mean sentence length = 6.9 words\n",
      "  Kernels [2,3,4] capture 2-4 word phrases (n-grams)\n",
      "  Examples: 'send message' (2), 'how to send' (3), 'create new instance now' (4)\n",
      "\n",
      "‚úì BATCH_SIZE = 32\n",
      "  Rationale: Dataset size = 2102 samples\n",
      "  65 batches per epoch\n",
      "  Provides good gradient estimation without excessive memory usage\n",
      "\n",
      "‚úì DROPOUT = 0.5\n",
      "  Rationale: Small dataset (2102 samples) ‚Üí high overfitting risk\n",
      "  Higher dropout (0.5) provides aggressive regularization\n",
      "\n",
      "9Ô∏è‚É£  CLASS BALANCE CHECK\n",
      "--------------------------------------------------------------------------------\n",
      "‚ö†Ô∏è  Classes are MODERATELY IMBALANCED (ratio 1.5-3x)\n",
      "   Imbalance ratio: 2.46x\n",
      "\n",
      "üîü SAMPLE QUERIES PER INTENT (3 examples each)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìå Intent: send_message\n",
      "   1. how do i send a message\n",
      "   2. can you send a message to my contacts\n",
      "   3. i want to send a bulk message\n",
      "\n",
      "üìå Intent: schedule_message\n",
      "   1. schedule a message\n",
      "   2. can i schedule messages\n",
      "   3. how to schedule\n",
      "\n",
      "üìå Intent: filter_number\n",
      "   1. filter numbers\n",
      "   2. how do i filter contacts\n",
      "   3. can you help me filter my contact list\n",
      "\n",
      "üìå Intent: create_instance\n",
      "   1. create instance\n",
      "   2. how do i create a new instance\n",
      "   3. can you help me create an instance\n",
      "\n",
      "üìå Intent: delete_instance\n",
      "   1. delete instance\n",
      "   2. how do i delete an instance\n",
      "   3. can you help me delete my instance\n",
      "\n",
      "================================================================================\n",
      "‚úÖ DATASET SANITY CHECK COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATASET SANITY CHECK & EXPLORATORY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä DATASET SANITY CHECK & ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(Config.DATASET_PATH)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£  BASIC STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Total intents: {df['intent'].nunique()}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n2Ô∏è‚É£  DATA QUALITY\")\n",
    "print(\"-\" * 80)\n",
    "missing = df.isnull().sum()\n",
    "print(\"Missing values:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  {col}: {missing[col]} ({missing[col]/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicates} ({duplicates/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Intent distribution\n",
    "print(\"\\n3Ô∏è‚É£  INTENT DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "intent_counts = df['intent'].value_counts()\n",
    "print(intent_counts)\n",
    "print(f\"\\nMost common: {intent_counts.index[0]} ({intent_counts.iloc[0]} samples)\")\n",
    "print(f\"Least common: {intent_counts.index[-1]} ({intent_counts.iloc[-1]} samples)\")\n",
    "print(f\"Class imbalance ratio: {intent_counts.iloc[0] / intent_counts.iloc[-1]:.2f}x\")\n",
    "\n",
    "# Text length analysis\n",
    "print(\"\\n4Ô∏è‚É£  TEXT LENGTH ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "\n",
    "print(f\"Character length:\")\n",
    "print(f\"  Min: {df['text_length'].min()}\")\n",
    "print(f\"  Max: {df['text_length'].max()}\")\n",
    "print(f\"  Mean: {df['text_length'].mean():.2f}\")\n",
    "print(f\"  Median: {df['text_length'].median():.0f}\")\n",
    "\n",
    "print(f\"\\nWord count:\")\n",
    "print(f\"  Min: {df['word_count'].min()}\")\n",
    "print(f\"  Max: {df['word_count'].max()}\")\n",
    "print(f\"  Mean: {df['word_count'].mean():.2f}\")\n",
    "print(f\"  Median: {df['word_count'].median():.0f}\")\n",
    "\n",
    "# Find longest sentences\n",
    "print(\"\\n5Ô∏è‚É£  LONGEST SENTENCES (Top 5)\")\n",
    "print(\"-\" * 80)\n",
    "longest = df.nlargest(5, 'word_count')[['text', 'intent', 'word_count']]\n",
    "for idx, row in longest.iterrows():\n",
    "    print(f\"\\n[{row['word_count']} words] Intent: {row['intent']}\")\n",
    "    print(f\"Text: {row['text']}\")\n",
    "\n",
    "# Find shortest sentences\n",
    "print(\"\\n6Ô∏è‚É£  SHORTEST SENTENCES (Top 5)\")\n",
    "print(\"-\" * 80)\n",
    "shortest = df.nsmallest(5, 'word_count')[['text', 'intent', 'word_count']]\n",
    "for idx, row in shortest.iterrows():\n",
    "    print(f\"\\n[{row['word_count']} words] Intent: {row['intent']}\")\n",
    "    print(f\"Text: {row['text']}\")\n",
    "\n",
    "# Vocabulary analysis\n",
    "print(\"\\n7Ô∏è‚É£  VOCABULARY STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "all_words = []\n",
    "for text in df['text']:\n",
    "    all_words.extend(str(text).lower().split())\n",
    "\n",
    "unique_words = set(all_words)\n",
    "print(f\"Total words (with repetition): {len(all_words)}\")\n",
    "print(f\"Unique words: {len(unique_words)}\")\n",
    "print(f\"Vocabulary richness: {len(unique_words)/len(all_words):.4f}\")\n",
    "\n",
    "# Most common words\n",
    "from collections import Counter\n",
    "word_freq = Counter(all_words)\n",
    "print(f\"\\nMost common words (Top 10):\")\n",
    "for word, count in word_freq.most_common(10):\n",
    "    print(f\"  '{word}': {count} times\")\n",
    "\n",
    "# Justification for hyperparameters\n",
    "print(\"\\n8Ô∏è‚É£  HYPERPARAMETER JUSTIFICATION\")\n",
    "print(\"-\" * 80)\n",
    "max_words = df['word_count'].max()\n",
    "mean_words = df['word_count'].mean()\n",
    "percentile_95 = df['word_count'].quantile(0.95)\n",
    "\n",
    "print(f\"‚úì MAX_SEQ_LENGTH = {Config.MAX_SEQ_LENGTH}\")\n",
    "print(f\"  Rationale: 95th percentile = {percentile_95:.0f} words\")\n",
    "print(f\"  Only {(df['word_count'] > Config.MAX_SEQ_LENGTH).sum()} samples ({(df['word_count'] > Config.MAX_SEQ_LENGTH).sum()/len(df)*100:.2f}%) exceed this length\")\n",
    "\n",
    "print(f\"\\n‚úì EMBEDDING_DIM = {Config.EMBEDDING_DIM}\")\n",
    "print(f\"  Rationale: Vocabulary size = {len(unique_words)}\")\n",
    "print(f\"  Rule of thumb: embedding_dim ‚âà vocab_size^0.25 = {len(unique_words)**0.25:.0f}\")\n",
    "print(f\"  100 dimensions provides good balance for vocab of ~1000 words\")\n",
    "\n",
    "print(f\"\\n‚úì KERNEL_SIZES = {Config.KERNEL_SIZES}\")\n",
    "print(f\"  Rationale: Mean sentence length = {mean_words:.1f} words\")\n",
    "print(f\"  Kernels [2,3,4] capture 2-4 word phrases (n-grams)\")\n",
    "print(f\"  Examples: 'send message' (2), 'how to send' (3), 'create new instance now' (4)\")\n",
    "\n",
    "print(f\"\\n‚úì BATCH_SIZE = {Config.BATCH_SIZE}\")\n",
    "print(f\"  Rationale: Dataset size = {len(df)} samples\")\n",
    "print(f\"  {len(df)//Config.BATCH_SIZE} batches per epoch\")\n",
    "print(f\"  Provides good gradient estimation without excessive memory usage\")\n",
    "\n",
    "print(f\"\\n‚úì DROPOUT = {Config.DROPOUT}\")\n",
    "print(f\"  Rationale: Small dataset ({len(df)} samples) ‚Üí high overfitting risk\")\n",
    "print(f\"  Higher dropout (0.5) provides aggressive regularization\")\n",
    "\n",
    "# Class balance visualization\n",
    "print(\"\\n9Ô∏è‚É£  CLASS BALANCE CHECK\")\n",
    "print(\"-\" * 80)\n",
    "min_samples = intent_counts.min()\n",
    "max_samples = intent_counts.max()\n",
    "imbalance = max_samples / min_samples\n",
    "\n",
    "if imbalance < 1.5:\n",
    "    print(\"‚úì Classes are WELL BALANCED (ratio < 1.5x)\")\n",
    "elif imbalance < 3:\n",
    "    print(\"‚ö†Ô∏è  Classes are MODERATELY IMBALANCED (ratio 1.5-3x)\")\n",
    "else:\n",
    "    print(\"‚ùå Classes are SEVERELY IMBALANCED (ratio > 3x)\")\n",
    "    print(\"   Consider: class weighting, oversampling minority, or undersampling majority\")\n",
    "\n",
    "print(f\"   Imbalance ratio: {imbalance:.2f}x\")\n",
    "\n",
    "# Sample queries per intent\n",
    "print(\"\\nüîü SAMPLE QUERIES PER INTENT (3 examples each)\")\n",
    "print(\"-\" * 80)\n",
    "for intent in df['intent'].unique()[:5]:  # Show first 5 intents\n",
    "    print(f\"\\nüìå Intent: {intent}\")\n",
    "    samples = df[df['intent'] == intent]['text'].head(3).tolist()\n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        print(f\"   {i}. {sample}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ DATASET SANITY CHECK COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Clean up temporary columns\n",
    "df = df.drop(['text_length', 'word_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6986c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHATTEA INTENT CLASSIFIER - CNN + WORD2VEC\n",
      "================================================================================\n",
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEVICE SETUP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CHATTEA INTENT CLASSIFIER - CNN + WORD2VEC\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aa4318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TEXT PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize whitespace\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenize text into words\"\"\"\n",
    "    return clean_text(text).split()\n",
    "\n",
    "def build_vocabulary(texts):\n",
    "    \"\"\"Extract all unique words from texts\"\"\"\n",
    "    vocab = set()\n",
    "    for text in texts:\n",
    "        vocab.update(re.findall(r'\\w+', str(text).lower()))\n",
    "    return vocab\n",
    "\n",
    "def fuzzy_correct(text, vocab, cutoff=Config.FUZZY_CUTOFF):\n",
    "    \"\"\"Correct typos using difflib.get_close_matches\"\"\"\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    corrected = []\n",
    "    for word in words:\n",
    "        matches = get_close_matches(word, vocab, n=1, cutoff=cutoff)\n",
    "        corrected.append(matches[0] if matches else word)\n",
    "    return ' '.join(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "485e6df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# WORD2VEC EMBEDDER\n",
    "# ============================================================================\n",
    "\n",
    "class Word2VecEmbedder:\n",
    "    \"\"\"Word2Vec embedding wrapper with proper initialization\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "        self.idx2word = {}\n",
    "        self.embedding_matrix = None\n",
    "        self.vocab_size = 0\n",
    "        self.embed_dim = Config.EMBEDDING_DIM\n",
    "\n",
    "    def train(self, sentences):\n",
    "        \"\"\"Train Word2Vec on tokenized sentences\"\"\"\n",
    "        print(\"\\nüß† Training Word2Vec...\")\n",
    "        self.model = Word2Vec(\n",
    "            sentences=sentences,\n",
    "            vector_size=Config.EMBEDDING_DIM,\n",
    "            window=Config.WORD2VEC_WINDOW,\n",
    "            min_count=Config.WORD2VEC_MIN_COUNT,\n",
    "            sg=Config.WORD2VEC_SG,\n",
    "            seed=Config.RANDOM_SEED,\n",
    "            workers=4\n",
    "        )\n",
    "\n",
    "        idx = 2\n",
    "        for word in self.model.wv.index_to_key:\n",
    "            self.word2idx[word] = idx\n",
    "            idx += 1\n",
    "\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "\n",
    "        self.embedding_matrix = np.zeros((self.vocab_size, self.embed_dim), dtype=np.float32)\n",
    "\n",
    "        for word, idx in self.word2idx.items():\n",
    "            if word in ['<PAD>', '<UNK>']:\n",
    "                if word == '<UNK>':\n",
    "                    self.embedding_matrix[idx] = np.random.randn(self.embed_dim) * 0.01\n",
    "            else:\n",
    "                try:\n",
    "                    self.embedding_matrix[idx] = self.model.wv[word]\n",
    "                except KeyError:\n",
    "                    self.embedding_matrix[idx] = np.random.randn(self.embed_dim) * 0.01\n",
    "\n",
    "        print(f\"‚úì Word2Vec trained: vocab={self.vocab_size}, dim={self.embed_dim}\")\n",
    "        return self\n",
    "\n",
    "    def save(self, path=Config.WORD2VEC_PATH):\n",
    "        if self.model:\n",
    "            self.model.save(path)\n",
    "            print(f\"‚úì Word2Vec saved to {path}\")\n",
    "\n",
    "    def load(self, path=Config.WORD2VEC_PATH):\n",
    "        print(f\"\\nüß† Loading Word2Vec from {path}...\")\n",
    "        self.model = Word2Vec.load(path)\n",
    "\n",
    "        self.word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "        idx = 2\n",
    "        for word in self.model.wv.index_to_key:\n",
    "            self.word2idx[word] = idx\n",
    "            idx += 1\n",
    "\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "\n",
    "        self.embedding_matrix = np.zeros((self.vocab_size, self.embed_dim), dtype=np.float32)\n",
    "\n",
    "        for word, idx in self.word2idx.items():\n",
    "            if word in ['<PAD>', '<UNK>']:\n",
    "                if word == '<UNK>':\n",
    "                    self.embedding_matrix[idx] = np.random.randn(self.embed_dim) * 0.01\n",
    "            else:\n",
    "                try:\n",
    "                    self.embedding_matrix[idx] = self.model.wv[word]\n",
    "                except KeyError:\n",
    "                    self.embedding_matrix[idx] = np.random.randn(self.embed_dim) * 0.01\n",
    "\n",
    "        print(f\"‚úì Word2Vec loaded: vocab={self.vocab_size}, dim={self.embed_dim}\")\n",
    "        return self\n",
    "\n",
    "    def encode_sequence(self, tokens, max_length=Config.MAX_SEQ_LENGTH):\n",
    "        indices = [self.word2idx.get(token, self.word2idx[\"<UNK>\"]) for token in tokens[:max_length]]\n",
    "        while len(indices) < max_length:\n",
    "            indices.append(self.word2idx[\"<PAD>\"])\n",
    "        return indices\n",
    "\n",
    "    def sentence_vector(self, tokens):\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in self.word2idx and token not in (\"<PAD>\", \"<UNK>\"):\n",
    "                idx = self.word2idx[token]\n",
    "                if idx < len(self.embedding_matrix):\n",
    "                    vectors.append(self.embedding_matrix[idx])\n",
    "        if len(vectors) == 0:\n",
    "            return np.zeros(self.embed_dim, dtype=np.float32)\n",
    "        return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd41d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CNN MODEL ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    \"\"\"CNN for Text Classification (Kim, 2014)\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "            print(\"‚úì CNN initialized with Word2Vec embeddings!\")\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=Config.NUM_FILTERS, kernel_size=k)\n",
    "            for k in Config.KERNEL_SIZES\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(Config.DROPOUT)\n",
    "        self.fc = nn.Linear(Config.NUM_FILTERS * len(Config.KERNEL_SIZES), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)                       # (batch, seq_len, embed_dim)\n",
    "        embedded = embedded.transpose(1, 2)                # (batch, embed_dim, seq_len)\n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            conv_out = F.relu(conv(embedded))              # (batch, num_filters, L)\n",
    "            pooled = F.max_pool1d(conv_out, conv_out.size(2)).squeeze(2)\n",
    "            conv_outputs.append(pooled)\n",
    "        concatenated = torch.cat(conv_outputs, dim=1)\n",
    "        dropped = self.dropout(concatenated)\n",
    "        logits = self.fc(dropped)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd74aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class IntentDataset(Dataset):\n",
    "    \"\"\"Simple dataset wrapper\"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5db8efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING CNN\n",
    "# ============================================================================\n",
    "\n",
    "def train_model_pretty(model, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Train the CNN classifier with MLP-style formatted output\"\"\"\n",
    "    model = model.to(config.DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_dataset = IntentDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üèãÔ∏è  TRAINING LOOP (WITH PROPER BATCHING!)\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"Epoch | Train Acc | Train Loss | Val Acc | Val Loss\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    for epoch in range(Config.EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X = batch_X.to(config.DEVICE)\n",
    "            batch_y = batch_y.to(config.DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (outputs.argmax(1) == batch_y).sum().item()\n",
    "            train_total += len(batch_y)\n",
    "\n",
    "        train_acc = train_correct / (train_total + 1e-12)\n",
    "        avg_train_loss = train_loss / (len(train_loader) + 1e-12)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_device = X_val.to(config.DEVICE)\n",
    "            y_val_device = y_val.to(config.DEVICE)\n",
    "            val_outputs = model(X_val_device)\n",
    "            val_loss = criterion(val_outputs, y_val_device).item()\n",
    "            val_acc = (val_outputs.argmax(1) == y_val_device).float().mean().item()\n",
    "\n",
    "        # Print progress (every 5 epochs + last)\n",
    "        if epoch % 5 == 0 or epoch == Config.EPOCHS - 1:\n",
    "            print(f\"{epoch:5d} | {train_acc:9.4f} | {avg_train_loss:10.4f} | {val_acc:7.4f} | {val_loss:8.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), Config.MODEL_PATH)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"‚úì Best Validation Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "    print(f\"‚úì Model saved to: {Config.MODEL_PATH}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(Config.MODEL_PATH, map_location=config.DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    # Final evaluation on train and val\n",
    "    with torch.no_grad():\n",
    "        final_train_pred = model(X_train.to(config.DEVICE)).argmax(1).cpu()\n",
    "        final_train_acc = (final_train_pred == y_train).float().mean().item()\n",
    "\n",
    "        final_val_pred = model(X_val.to(config.DEVICE)).argmax(1).cpu()\n",
    "        final_val_acc = (final_val_pred == y_val).float().mean().item()\n",
    "\n",
    "    print(\"\\n   Training Accuracy:   {:.4f} ({:.2f}%)\".format(final_train_acc, final_train_acc*100))\n",
    "    print(\"   Validation Accuracy: {:.4f} ({:.2f}%)\".format(final_val_acc, final_val_acc*100))\n",
    "    print(\"\\n‚úì Model ready for inference!\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHATBOT CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class ChatteaBot:\n",
    "    \"\"\"Main chatbot class with hybrid classification\"\"\"\n",
    "\n",
    "    def __init__(self, model, embedder, label_encoder, responses,\n",
    "                 df, sentence_vectors, vocab):\n",
    "        self.model = model\n",
    "        self.embedder = embedder\n",
    "        self.le = label_encoder  # sklearn LabelEncoder instance\n",
    "        self.responses = responses\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.sentence_vectors = sentence_vectors.astype(np.float32) if sentence_vectors is not None else np.zeros((len(self.df), embedder.embed_dim))\n",
    "        self.vocab = vocab\n",
    "\n",
    "        # Intent mapping\n",
    "        if hasattr(self.le, \"classes_\"):\n",
    "            self.intent_map = {i: label for i, label in enumerate(self.le.classes_)}\n",
    "        elif isinstance(self.le, dict):\n",
    "            self.intent_map = {v: k for k, v in self.le.items()}\n",
    "        else:\n",
    "            self.intent_map = {}\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def _get_response(self, intent):\n",
    "        \"\"\"Get response for intent\"\"\"\n",
    "        response = self.responses.get(intent, self.responses.get(\"help\", \"I'm not sure how to help with that.\"))\n",
    "        if isinstance(response, dict):\n",
    "            return response.get(\"en\", response.get(\"id\", next(iter(response.values()))))\n",
    "        return response\n",
    "\n",
    "    def get_reply(self, user_input):\n",
    "        \"\"\"Get chatbot response\"\"\"\n",
    "        text = str(user_input).strip()\n",
    "\n",
    "        if text == \"\":\n",
    "            return \"Say something :)\"\n",
    "\n",
    "        # Rule-based greeting\n",
    "        if any(g in text.lower() for g in [\"hai\", \"halo\", \"hello\", \"hi\", \"hey\", \"pagi\", \"siang\", \"malam\"]):\n",
    "            return self._get_response(\"greeting\")\n",
    "\n",
    "        # Fuzzy correction\n",
    "        corrected = fuzzy_correct(text, self.vocab, Config.FUZZY_CUTOFF)\n",
    "        tokens = tokenize(corrected)\n",
    "\n",
    "        # Model prediction\n",
    "        sequence = self.embedder.encode_sequence(tokens, Config.MAX_SEQ_LENGTH)\n",
    "        x = torch.LongTensor([sequence]).to(config.DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(x)\n",
    "            probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "            model_conf = float(probs.max())\n",
    "            model_idx = int(np.argmax(probs))\n",
    "            # map to label string\n",
    "            try:\n",
    "                model_intent = self.intent_map[model_idx]\n",
    "            except Exception:\n",
    "                model_intent = str(model_idx)\n",
    "\n",
    "        # Retrieval fallback (sentence vectors from embedder average)\n",
    "        user_vec = self.embedder.sentence_vector(tokens).reshape(1, -1)\n",
    "\n",
    "        if self.sentence_vectors is None or len(self.sentence_vectors) == 0:\n",
    "            retrieval_intent = model_intent\n",
    "            retrieval_score = 0.0\n",
    "        else:\n",
    "            similarities = cosine_similarity(user_vec, self.sentence_vectors)[0]\n",
    "            best_idx = int(np.argmax(similarities))\n",
    "            retrieval_score = float(similarities[best_idx])\n",
    "            retrieval_intent = str(self.df.iloc[best_idx][\"intent\"])\n",
    "\n",
    "        # Decision\n",
    "        if model_conf >= Config.CONFIDENCE_THRESHOLD:\n",
    "            final_intent = model_intent\n",
    "            decision = \"MODEL\"\n",
    "        else:\n",
    "            final_intent = retrieval_intent\n",
    "            decision = \"RETRIEVAL\"\n",
    "\n",
    "        return self._get_response(final_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# UTILS: Pretty evaluation & inference output\n",
    "# ============================================================================\n",
    "\n",
    "def pretty_inference_tests(bot, test_queries=None):\n",
    "    if test_queries is None:\n",
    "        test_queries = [\n",
    "            \"hello\",\n",
    "            \"what is chattea\",\n",
    "            \"how to blast message\",\n",
    "            \"create instance\",\n",
    "            \"send bulk messages\"\n",
    "        ]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üß™ TESTING INFERENCE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nRunning test queries:\\n\")\n",
    "\n",
    "    for query in test_queries:\n",
    "        print(f\"üë§ User: {query}\")\n",
    "        try:\n",
    "            response = bot.get_reply(query)\n",
    "            # truncate like your example\n",
    "            out = response if isinstance(response, str) else str(response)\n",
    "            print(f\"ü§ñ Bot: {out[:200]}{'...' if len(out) > 200 else ''}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error during inference:\", e)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "def pretty_evaluation(model, X_val, y_val, le, df):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val.to(config.DEVICE))\n",
    "        preds = outputs.argmax(1).cpu().numpy()\n",
    "        labels = y_val.numpy()\n",
    "\n",
    "    val_acc = accuracy_score(labels, preds)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä MODEL EVALUATION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"‚úì Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\\n\")\n",
    "    print(\"üìã Per-Intent Performance:\")\n",
    "\n",
    "    intent_names = list(le.classes_)\n",
    "    for i, intent_name in enumerate(intent_names):\n",
    "        mask = labels == i\n",
    "        count = int(mask.sum())\n",
    "        if count == 0:\n",
    "            continue\n",
    "        intent_acc = (preds[mask] == labels[mask]).mean()\n",
    "        print(f\"   {intent_name:30s}: {intent_acc:.3f} ({count:2d} samples)\")\n",
    "\n",
    "    # Full training set accuracy if available as X_all global\n",
    "    try:\n",
    "        if 'X' in globals():\n",
    "            with torch.no_grad():\n",
    "                all_outputs = model(X.to(config.DEVICE))\n",
    "                all_preds = all_outputs.argmax(1).cpu().numpy()\n",
    "                all_labels = np.array([int(x) for x in df['label'].values])\n",
    "                train_acc = (all_preds == all_labels).mean()\n",
    "                print(f\"\\nAccuracy on FULL training set: {train_acc:.4f}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ EVALUATION COMPLETE\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88263843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading data...\n",
      "‚úì Loaded 2102 samples, 14 intents\n",
      "\n",
      "üìö Building vocabulary...\n",
      "‚úì Vocabulary: 1037 words\n",
      "\n",
      "üè∑Ô∏è  Encoding labels...\n",
      "‚úì Classes: 14\n",
      "\n",
      "‚úÇÔ∏è  Tokenizing...\n",
      "\n",
      "üß† Training Word2Vec...\n",
      "‚úì Word2Vec trained: vocab=1043, dim=100\n",
      "‚úì Word2Vec saved to word2vec.model\n",
      "\n",
      "üìä Preparing sequences...\n",
      "‚úì CNN initialized with Word2Vec embeddings!\n",
      "\n",
      "‚ö†Ô∏è  No pre-trained model found. Training from scratch...\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è  TRAINING LOOP (WITH PROPER BATCHING!)\n",
      "================================================================================\n",
      "\n",
      "Epoch | Train Acc | Train Loss | Val Acc | Val Loss\n",
      "-----------------------------------------------------------------\n",
      "    0 |    0.0833 |     2.5948 |  0.1544 |   2.5428\n",
      "    5 |    0.9358 |     0.2424 |  0.9549 |   0.1789\n",
      "   10 |    0.9970 |     0.0301 |  0.9786 |   0.0754\n",
      "   15 |    1.0000 |     0.0075 |  0.9786 |   0.0668\n",
      "   20 |    0.9994 |     0.0062 |  0.9834 |   0.0651\n",
      "   25 |    0.9988 |     0.0051 |  0.9810 |   0.0616\n",
      "   29 |    0.9988 |     0.0062 |  0.9786 |   0.0629\n",
      "\n",
      "================================================================================\n",
      "‚úì Best Validation Accuracy: 0.9834 (98.34%)\n",
      "‚úì Model saved to: cnn_chattea.pth\n",
      "================================================================================\n",
      "\n",
      "   Training Accuracy:   1.0000 (100.00%)\n",
      "   Validation Accuracy: 0.9834 (98.34%)\n",
      "\n",
      "‚úì Model ready for inference!\n",
      "\n",
      "üìê Preparing sentence vectors for retrieval...\n",
      "\n",
      "ü§ñ Initializing chatbot...\n",
      "‚úì Chatbot ready!\n",
      "\n",
      "================================================================================\n",
      "üß™ TESTING INFERENCE\n",
      "================================================================================\n",
      "\n",
      "Running test queries:\n",
      "\n",
      "üë§ User: hello\n",
      "ü§ñ Bot: Hello! üëã Welcome to Chattea.\n",
      "\n",
      "I'm here to help you navigate features like sending messages, managing instances, filtering contacts, scheduling messages, and more.\n",
      "\n",
      "How can I assist you today?\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: what is chattea\n",
      "ü§ñ Bot: Chattea is a WhatsApp marketing automation platform designed for businesses.\n",
      "\n",
      "üéØ Key features:\n",
      "‚Ä¢ Send mass messages (blast)\n",
      "‚Ä¢ Schedule messages\n",
      "‚Ä¢ Manage multiple WhatsApp instances\n",
      "‚Ä¢ Filter & validate ...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: how to blast message\n",
      "ü§ñ Bot: To send a message:\n",
      "\n",
      "1. Choose an active instance\n",
      "2. Enter the destination number (e.g., 628123456789)\n",
      "3. Type your message\n",
      "4. Click **Send**\n",
      "\n",
      "The message will be delivered immediately.\n",
      "\n",
      "üí° Tip: Use var...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: create instance\n",
      "ü§ñ Bot: To create a new WhatsApp instance:\n",
      "\n",
      "1. Open the **Instances** tab\n",
      "2. Click **+ New Instance**\n",
      "3. Enter a name (e.g., Marketing, Support, Sales)\n",
      "4. Scan the QR code with WhatsApp via:\n",
      "   Settings ‚Üí Lin...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: send bulk messages\n",
      "ü§ñ Bot: To send a message:\n",
      "\n",
      "1. Choose an active instance\n",
      "2. Enter the destination number (e.g., 628123456789)\n",
      "3. Type your message\n",
      "4. Click **Send**\n",
      "\n",
      "The message will be delivered immediately.\n",
      "\n",
      "üí° Tip: Use var...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "üìä MODEL EVALUATION\n",
      "================================================================================\n",
      "‚úì Validation Accuracy: 0.9834 (98.34%)\n",
      "\n",
      "üìã Per-Intent Performance:\n",
      "   contact                       : 1.000 (32 samples)\n",
      "   create_group                  : 1.000 (32 samples)\n",
      "   create_instance               : 1.000 (32 samples)\n",
      "   delete_group                  : 1.000 (32 samples)\n",
      "   delete_instance               : 0.969 (32 samples)\n",
      "   edit_group                    : 1.000 (32 samples)\n",
      "   edit_instance                 : 1.000 (32 samples)\n",
      "   filter_number                 : 1.000 (32 samples)\n",
      "   greeting                      : 0.846 (13 samples)\n",
      "   pricing                       : 1.000 (32 samples)\n",
      "   schedule_message              : 1.000 (32 samples)\n",
      "   send_message                  : 1.000 (32 samples)\n",
      "   unknown                       : 0.875 (24 samples)\n",
      "   what_for                      : 0.969 (32 samples)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ EVALUATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\nüìÇ Loading data...\")\n",
    "    if not os.path.exists(Config.DATASET_PATH):\n",
    "        raise FileNotFoundError(f\"Dataset not found: {Config.DATASET_PATH}\")\n",
    "\n",
    "    df = pd.read_csv(Config.DATASET_PATH)\n",
    "    if \"text\" not in df.columns or \"intent\" not in df.columns:\n",
    "        raise ValueError(\"Dataset must have 'text' and 'intent' columns\")\n",
    "\n",
    "    print(f\"‚úì Loaded {len(df)} samples, {df['intent'].nunique()} intents\")\n",
    "\n",
    "    # Load responses\n",
    "    if not os.path.exists(Config.RESPONSES_PATH):\n",
    "        raise FileNotFoundError(f\"Responses file not found: {Config.RESPONSES_PATH}\")\n",
    "\n",
    "    with open(Config.RESPONSES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        responses = json.load(f)\n",
    "\n",
    "    # Build vocabulary (for fuzzy)\n",
    "    print(\"\\nüìö Building vocabulary...\")\n",
    "    vocab = build_vocabulary(df['text'].tolist())\n",
    "    print(f\"‚úì Vocabulary: {len(vocab)} words\")\n",
    "\n",
    "    # Label encoding\n",
    "    print(\"\\nüè∑Ô∏è  Encoding labels...\")\n",
    "    le = LabelEncoder()\n",
    "    df['label'] = le.fit_transform(df['intent'].astype(str))\n",
    "    num_classes = len(le.classes_)\n",
    "    print(f\"‚úì Classes: {num_classes}\")\n",
    "\n",
    "    # Tokenize\n",
    "    print(\"\\n‚úÇÔ∏è  Tokenizing...\")\n",
    "    df['tokens'] = df['text'].apply(lambda t: tokenize(str(t)))\n",
    "\n",
    "    # Word2Vec\n",
    "    embedder = Word2VecEmbedder()\n",
    "    if os.path.exists(Config.WORD2VEC_PATH):\n",
    "        embedder.load(Config.WORD2VEC_PATH)\n",
    "    else:\n",
    "        embedder.train(df['tokens'].tolist())\n",
    "        embedder.save(Config.WORD2VEC_PATH)\n",
    "\n",
    "    # Prepare sequences\n",
    "    print(\"\\nüìä Preparing sequences...\")\n",
    "    sequences = np.array([embedder.encode_sequence(tokens, Config.MAX_SEQ_LENGTH) for tokens in df['tokens']], dtype=np.int64)\n",
    "\n",
    "    X = torch.tensor(sequences, dtype=torch.long)\n",
    "    y = torch.tensor(df['label'].values, dtype=torch.long)\n",
    "\n",
    "    # Train/val split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        range(len(df)),\n",
    "        test_size=Config.TEST_SIZE,\n",
    "        random_state=Config.RANDOM_SEED,\n",
    "        stratify=df['label']\n",
    "    )\n",
    "    \n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_val = X[val_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "    # Build model\n",
    "    model = TextCNN(vocab_size=embedder.vocab_size, embedding_dim=Config.EMBEDDING_DIM, num_classes=num_classes, embedding_matrix=embedder.embedding_matrix)\n",
    "\n",
    "    # Train or load model\n",
    "    if os.path.exists(Config.MODEL_PATH):\n",
    "        print(f\"\\n‚úì Found existing model: {Config.MODEL_PATH}\")\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(Config.MODEL_PATH, map_location=config.DEVICE))\n",
    "            model.eval()\n",
    "            print(\"‚úì Model loaded!\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to load model, will retrain:\", e)\n",
    "            model = train_model_pretty(model, X_train, y_train, X_val, y_val)\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No pre-trained model found. Training from scratch...\")\n",
    "        model = train_model_pretty(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Prepare sentence vectors for retrieval\n",
    "    print(\"\\nüìê Preparing sentence vectors for retrieval...\")\n",
    "    sent_vecs = np.stack([embedder.sentence_vector(tokens) for tokens in df['tokens']])\n",
    "    norms = np.linalg.norm(sent_vecs, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    sent_vecs_normalized = sent_vecs / norms\n",
    "\n",
    "    # Create bot\n",
    "    print(\"\\nü§ñ Initializing chatbot...\")\n",
    "    bot = ChatteaBot(model, embedder, le, responses, df, sent_vecs_normalized, vocab)\n",
    "    print(\"‚úì Chatbot ready!\")\n",
    "\n",
    "    # Inference tests\n",
    "    pretty_inference_tests(bot)\n",
    "\n",
    "    # Evaluation\n",
    "    pretty_evaluation(model, X_val, y_val, le, df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8beabe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Cleared GPU cache\n",
      "Deleted Old Word2Vec Model\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FRESH START - DELETE EVERYTHING AND RETRAIN\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. Delete saved model\n",
    "if os.path.exists(\"chattea.pth\"):\n",
    "    os.remove(\"chattea.pth\")\n",
    "    print(\"‚úì Deleted old model\")\n",
    "\n",
    "# 2. Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "# 3. Delete saved word2vec.model\n",
    "if os.path.exists(\"word2vec.model\"):\n",
    "    os.remove(\"word2vec.model\")\n",
    "    print(\"Deleted Old Word2Vec Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
