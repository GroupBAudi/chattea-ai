{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ae806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chattea Intent Classifier - CNN + Sentence Transformers\n",
    "# Complete Working Pipeline in Notebook Format\n",
    "# Ready to run cell by cell!\n",
    "\n",
    "\"\"\"\n",
    "JUPYTER NOTEBOOK STRUCTURE:\n",
    "Run each cell in order (Shift+Enter)\n",
    "\n",
    "Required Files:\n",
    "- chatbot_dataset.csv (text, intent columns)\n",
    "- responses.json (your bilingual responses)\n",
    "\n",
    "Installation:\n",
    "!pip install torch sentence-transformers scikit-learn pandas difflib\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from difflib import get_close_matches\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CHATTEA INTENT CLASSIFIER - CNN + SENTENCE TRANSFORMERS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d69dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 2: DEVICE CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - training will use CPU (slower)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e254ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìÇ LOADING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load training dataset\n",
    "df = pd.read_csv(\"chatbot_dataset.csv\")\n",
    "print(f\"‚úì Loaded dataset: {len(df)} samples\")\n",
    "print(f\"‚úì Columns: {list(df.columns)}\")\n",
    "print(f\"‚úì Unique intents: {df['intent'].nunique()}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìä Sample data:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Intent distribution\n",
    "print(\"\\nüìà Intent distribution:\")\n",
    "intent_counts = df['intent'].value_counts()\n",
    "print(intent_counts.head(15))\n",
    "\n",
    "# Load responses\n",
    "with open(\"responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    RESPONSES = json.load(f)\n",
    "print(f\"\\n‚úì Loaded responses for {len(RESPONSES)} intents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4bab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 4: BUILD VOCABULARY FOR FUZZY MATCHING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö BUILDING VOCABULARY FOR FUZZY MATCHING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Extract all unique words from training data for typo correction\n",
    "all_words = set()\n",
    "for text in df['text'].str.lower():\n",
    "    all_words.update(re.findall(r'\\w+', text))\n",
    "\n",
    "VOCAB = all_words\n",
    "print(f\"‚úì Vocabulary size: {len(VOCAB)} unique words\")\n",
    "print(f\"‚úì Sample words: {list(VOCAB)[:20]}\")\n",
    "\n",
    "def fuzzy_correct(text: str, cutoff: float = 0.8) -> str:\n",
    "    \"\"\"\n",
    "    Typo correction using difflib (Fuzzy String Matching)\n",
    "    \n",
    "    Algorithm: Levenshtein Distance\n",
    "    - Finds closest matching words from vocabulary\n",
    "    - Corrects typos while preserving sentence structure\n",
    "    \n",
    "    Example: \"blst mesage\" ‚Üí \"blast message\"\n",
    "    \"\"\"\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    corrected = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Find closest match in vocabulary\n",
    "        matches = get_close_matches(word, VOCAB, n=1, cutoff=cutoff)\n",
    "        corrected.append(matches[0] if matches else word)\n",
    "    \n",
    "    # Reconstruct sentence preserving original punctuation\n",
    "    result = text\n",
    "    for orig, corr in zip(words, corrected):\n",
    "        if orig != corr:\n",
    "            result = re.sub(rf'\\b{orig}\\b', corr, result, count=1, flags=re.IGNORECASE)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test fuzzy correction\n",
    "print(\"\\nüß™ Testing Fuzzy Correction:\")\n",
    "test_cases = [\n",
    "    \"blst mesage\",\n",
    "    \"chek number\",\n",
    "    \"craete instance\",\n",
    "    \"shedule mesage\"\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    corrected = fuzzy_correct(test)\n",
    "    print(f\"   '{test}' ‚Üí '{corrected}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec725652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 5: LABEL ENCODING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üè∑Ô∏è  ENCODING LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Encode intent labels to numeric values\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['intent'])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "intent_map = dict(enumerate(le.classes_))\n",
    "\n",
    "print(f\"‚úì Number of classes: {num_classes}\")\n",
    "print(f\"\\nüìã Intent mapping (first 10):\")\n",
    "for idx, intent in list(intent_map.items())[:10]:\n",
    "    print(f\"   {idx}: {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ecd8fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded embedding model\n",
      "‚úì Embedding dimension: 384\n",
      "\n",
      "üìä Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:00<00:00, 107.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generated embeddings: torch.Size([2102, 384])\n",
      "   - Shape: (num_samples, embedding_dim)\n",
      "   - Device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 6: SENTENCE EMBEDDINGS (WORD2VEC ALTERNATIVE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß† GENERATING SENTENCE EMBEDDINGS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Using: Sentence Transformers (all-MiniLM-L6-v2)\")\n",
    "print(\"This is a neural embedding model (similar to Word2Vec but sentence-level)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load pre-trained sentence embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"‚úì Loaded embedding model\")\n",
    "print(f\"‚úì Embedding dimension: 384\")\n",
    "\n",
    "# Generate embeddings for all training samples\n",
    "print(\"\\nüìä Encoding training data...\")\n",
    "sentence_embeddings = embedder.encode(\n",
    "    df['text'].tolist(), \n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True\n",
    ").to(device)\n",
    "\n",
    "print(f\"‚úì Generated embeddings: {sentence_embeddings.shape}\")\n",
    "print(f\"   - Shape: (num_samples, embedding_dim)\")\n",
    "print(f\"   - Device: {sentence_embeddings.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e70c8943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèóÔ∏è  CNN MODEL ARCHITECTURE\n",
      "================================================================================\n",
      "\n",
      "üìê Model Architecture:\n",
      "TextCNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv1d(1, 128, kernel_size=(3,), stride=(1,))\n",
      "    (1): Conv1d(1, 128, kernel_size=(4,), stride=(1,))\n",
      "    (2): Conv1d(1, 128, kernel_size=(5,), stride=(1,))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=384, out_features=14, bias=True)\n",
      ")\n",
      "\n",
      "‚úì Model defined successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 7: CNN MODEL ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèóÔ∏è  CNN MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for Text Classification\n",
    "    \n",
    "    Architecture:\n",
    "    1. Input: Sentence embeddings (384-dim vectors)\n",
    "    2. Multiple Conv1D layers with different kernel sizes (3, 4, 5)\n",
    "       - Detects patterns of different n-gram lengths\n",
    "    3. Max pooling: Extract most important features\n",
    "    4. Dropout: Prevent overfitting (40%)\n",
    "    5. Fully connected layer: Final classification\n",
    "    \n",
    "    Why CNN for text?\n",
    "    - Detects local patterns (like phrases)\n",
    "    - Translation invariant (same pattern anywhere in text)\n",
    "    - Faster than RNN/LSTM\n",
    "    - Simpler than Transformers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim=384, num_classes=num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multiple convolution layers with different kernel sizes\n",
    "        # This captures n-grams of different lengths\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=1, out_channels=128, kernel_size=k) \n",
    "            for k in [3, 4, 5]\n",
    "        ])\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(128 * 3, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 384)\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, 384)\n",
    "        \n",
    "        # Apply convolutions and max pooling\n",
    "        convs = [F.relu(conv(x)).max(dim=2)[0] for conv in self.convs]\n",
    "        \n",
    "        # Concatenate all conv outputs\n",
    "        x = torch.cat(convs, dim=1)  # (batch_size, 128*3)\n",
    "        \n",
    "        # Dropout and classification\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nüìê Model Architecture:\")\n",
    "print(TextCNN())\n",
    "print(\"\\n‚úì Model defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8653370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ TRAINING CNN MODEL\n",
      "================================================================================\n",
      "‚ö†Ô∏è  No pre-trained model found. Training from scratch...\n",
      "\n",
      "================================================================================\n",
      "üìö PREPARING TRAINING DATA\n",
      "================================================================================\n",
      "‚úì X shape: torch.Size([2102, 384])\n",
      "‚úì y shape: torch.Size([2102])\n",
      "\n",
      "‚úì Training samples: 1681\n",
      "‚úì Validation samples: 421\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è  TRAINING LOOP\n",
      "================================================================================\n",
      "\n",
      "Epoch | Accuracy | Loss\n",
      "----------------------------------------\n",
      "    0 |   0.0690 |   2.6664\n",
      "    5 |   0.0708 |   2.6338\n",
      "   10 |   0.0839 |   2.6238\n",
      "   15 |   0.0904 |   2.6183\n",
      "   20 |   0.0797 |   2.6170\n",
      "   25 |   0.0993 |   2.6126\n",
      "\n",
      "================================================================================\n",
      "‚úì Final Training Accuracy: 0.0928 (9.28%)\n",
      "‚úì Final Validation Accuracy: 0.0855 (8.55%)\n",
      "================================================================================\n",
      "\n",
      "‚úì Model saved to: cnn_chattea.pth\n",
      "\n",
      "‚úì Model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 8: TRAIN OR LOAD MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ TRAINING CNN MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_path = \"cnn_chattea.pth\"\n",
    "\n",
    "try:\n",
    "    # Try to load pre-trained model\n",
    "    cnn_model = TextCNN().to(device)\n",
    "    cnn_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(\"‚úì Loaded pre-trained CNN model from\", model_path)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è  No pre-trained model found. Training from scratch...\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìö PREPARING TRAINING DATA\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Encode all texts\n",
    "    X = embedder.encode(df['text'].tolist(), convert_to_tensor=True).to(device)\n",
    "    y = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    print(f\"‚úì X shape: {X.shape}\")\n",
    "    print(f\"‚úì y shape: {y.shape}\")\n",
    "    \n",
    "    # Train/validation split (stratified)\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        torch.arange(len(X)),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y.cpu()  # Stratify to maintain class distribution\n",
    "    )\n",
    "    \n",
    "    X_train = X[train_idx].to(device)\n",
    "    X_val = X[val_idx].to(device)\n",
    "    y_train = y[train_idx].to(device)\n",
    "    y_val = y[val_idx].to(device)\n",
    "    \n",
    "    print(f\"\\n‚úì Training samples: {len(X_train)}\")\n",
    "    print(f\"‚úì Validation samples: {len(X_val)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üèãÔ∏è  TRAINING LOOP\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Initialize model\n",
    "    cnn_model = TextCNN().to(device)\n",
    "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.002)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    cnn_model.train()\n",
    "    print(\"\\nEpoch | Accuracy | Loss\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for epoch in range(30):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = cnn_model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = (outputs.argmax(1) == y_train).float().mean().item()\n",
    "        \n",
    "        # Print progress every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"{epoch:5d} | {acc:8.4f} | {loss.item():8.4f}\")\n",
    "    \n",
    "    # Final training accuracy\n",
    "    with torch.no_grad():\n",
    "        outputs = cnn_model(X_train)\n",
    "        train_acc = (outputs.argmax(1) == y_train).float().mean().item()\n",
    "        \n",
    "        # Validation accuracy\n",
    "        val_outputs = cnn_model(X_val)\n",
    "        val_acc = (val_outputs.argmax(1) == y_val).float().mean().item()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"‚úì Final Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "    print(f\"‚úì Final Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(cnn_model.state_dict(), model_path)\n",
    "    print(f\"\\n‚úì Model saved to: {model_path}\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "cnn_model.eval()\n",
    "print(\"\\n‚úì Model ready for inference!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bc1c810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üí¨ CHAT INFERENCE FUNCTION\n",
      "================================================================================\n",
      "‚úì Chat function ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: MAIN CHAT FUNCTION (INFERENCE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí¨ CHAT INFERENCE FUNCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def get_chattea_reply(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Main chatbot inference function\n",
    "    \n",
    "    Pipeline:\n",
    "    1. Rule-based filters (greetings, goodbyes)\n",
    "    2. Phone number extraction (if applicable)\n",
    "    3. CNN classification with confidence check\n",
    "    4. Retrieval fallback (if low confidence)\n",
    "    5. Response generation\n",
    "    \n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        \n",
    "    Returns:\n",
    "        Bot's response\n",
    "    \"\"\"\n",
    "    text = user_input.strip().lower()\n",
    "    \n",
    "    # ==================== RULE-BASED FILTERS ====================\n",
    "    # Quick responses for common greetings\n",
    "    if any(g in text for g in [\"hai\", \"halo\", \"hello\", \"hi\", \"hey\", \"pagi\", \"siang\", \"malam\"]):\n",
    "        return RESPONSES[\"greeting\"][\"en\"]\n",
    "    \n",
    "    if any(g in text for g in [\"bye\", \"goodbye\", \"dadah\", \"sampai jumpa\"]):\n",
    "        return RESPONSES[\"unknown\"][\"en\"]\n",
    "    \n",
    "    # ==================== EMBEDDING + PREDICTION ====================\n",
    "    with torch.no_grad():\n",
    "        # Encode user input\n",
    "        user_emb = embedder.encode(user_input, convert_to_tensor=True).to(device)\n",
    "        user_emb = user_emb.unsqueeze(0)  # (1, 384)\n",
    "        \n",
    "        # CNN prediction\n",
    "        cnn_logits = cnn_model(user_emb)\n",
    "        cnn_probs = cnn_logits.softmax(1)\n",
    "        cnn_confidence = cnn_probs.max().item()\n",
    "        cnn_intent = intent_map[cnn_logits.argmax(1).item()]\n",
    "        \n",
    "        # Retrieval fallback (semantic similarity)\n",
    "        cos_scores = util.cos_sim(user_emb, sentence_embeddings)[0]\n",
    "        best_match_idx = cos_scores.argmax().item()\n",
    "        retrieval_intent = df.iloc[best_match_idx]['intent']\n",
    "        retrieval_score = cos_scores[best_match_idx].item()\n",
    "        \n",
    "        # Choose final intent based on confidence\n",
    "        if cnn_confidence > 0.90:\n",
    "            final_intent = cnn_intent\n",
    "            source = \"CNN\"\n",
    "        else:\n",
    "            final_intent = retrieval_intent\n",
    "            source = \"Retrieval\"\n",
    "    \n",
    "    # ==================== SPECIAL CASES ====================\n",
    "\n",
    "    # ==================== RESPONSE GENERATION ====================\n",
    "    response = RESPONSES.get(final_intent, RESPONSES.get(\"help\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    # Handle both dict (bilingual) and string responses\n",
    "    if isinstance(response, dict):\n",
    "        return response.get(\"en\", response.get(\"id\", \"I'm not sure how to help with that.\"))\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"‚úì Chat function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0fbf495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß™ TESTING INFERENCE\n",
      "================================================================================\n",
      "\n",
      "Running test queries:\n",
      "\n",
      "üë§ User: hello\n",
      "ü§ñ Bot: Hello! üëã Welcome to Chattea.\n",
      "\n",
      "I'm here to help you navigate features like sending messages, managing...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: what is chattea\n",
      "ü§ñ Bot: Chattea is a WhatsApp marketing automation platform designed for businesses.\n",
      "\n",
      "üéØ Key features:\n",
      "‚Ä¢ Send...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: how to blast message\n",
      "ü§ñ Bot: To send a message:\n",
      "\n",
      "1. Choose an active instance\n",
      "2. Enter the destination number (e.g., 628123456789...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: check 08123456789\n",
      "ü§ñ Bot: To filter/check phone numbers:\n",
      "\n",
      "1. Open **Tools** ‚Üí **Phone Checker**\n",
      "2. Enter a phone number or upl...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: create instance\n",
      "ü§ñ Bot: To create a new WhatsApp instance:\n",
      "\n",
      "1. Open the **Instances** tab\n",
      "2. Click **+ New Instance**\n",
      "3. Ent...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: schedule message\n",
      "ü§ñ Bot: To schedule a message:\n",
      "\n",
      "1. Compose your message normally\n",
      "2. Click the **Schedule (‚è∞)** button\n",
      "3. Sel...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: thanks\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n",
      "üë§ User: goodbye\n",
      "ü§ñ Bot: I'm not sure I understood that correctly. ü§î\n",
      "\n",
      "I can help you with:\n",
      "‚Ä¢ Sending messages\n",
      "‚Ä¢ Scheduling me...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 11: TEST INFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß™ TESTING INFERENCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_queries = [\n",
    "    \"hello\",\n",
    "    \"what is chattea\",\n",
    "    \"how to blast message\",\n",
    "    \"check 08123456789\",\n",
    "    \"create instance\",\n",
    "    \"schedule message\",\n",
    "    \"thanks\",\n",
    "    \"goodbye\"\n",
    "]\n",
    "\n",
    "print(\"\\nRunning test queries:\\n\")\n",
    "for query in test_queries:\n",
    "    print(f\"üë§ User: {query}\")\n",
    "    response = get_chattea_reply(query)\n",
    "    print(f\"ü§ñ Bot: {response[:100]}{'...' if len(response) > 100 else ''}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc463ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä MODEL EVALUATION\n",
      "================================================================================\n",
      "‚úì Validation Accuracy: 0.1805 (18.05%)\n",
      "\n",
      "üìã Per-Intent Performance:\n",
      "   contact                       : 0.188 (32 samples)\n",
      "   create_group                  : 0.031 (32 samples)\n",
      "   create_instance               : 0.094 (32 samples)\n",
      "   delete_group                  : 0.000 (32 samples)\n",
      "   delete_instance               : 0.875 (32 samples)\n",
      "   edit_group                    : 0.375 (32 samples)\n",
      "   edit_instance                 : 0.000 (32 samples)\n",
      "   filter_number                 : 0.031 (32 samples)\n",
      "   greeting                      : 0.000 (13 samples)\n",
      "   pricing                       : 0.031 (32 samples)\n",
      "   schedule_message              : 0.062 (32 samples)\n",
      "   send_message                  : 0.031 (32 samples)\n",
      "   unknown                       : 0.000 (24 samples)\n",
      "   what_for                      : 0.656 (32 samples)\n",
      "Accuracy on FULL training set: 0.1931\n",
      "\n",
      "================================================================================\n",
      "‚úÖ NOTEBOOK COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Your model is ready to use!\n",
      "‚úì Deleted old model\n",
      "‚úì Cleared GPU cache\n",
      "\n",
      "‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 13: MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä MODEL EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluate on validation set\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    X_all = embedder.encode(df['text'].tolist(), convert_to_tensor=True).to(device)\n",
    "    y_all = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        torch.arange(len(X_all)),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_all.cpu()\n",
    "    )\n",
    "    \n",
    "    X_val = X_all[val_idx].to(device)\n",
    "    y_val = y_all[val_idx].to(device)\n",
    "    \n",
    "    # Predict\n",
    "    val_outputs = cnn_model(X_val)\n",
    "    val_preds = val_outputs.argmax(1)\n",
    "    \n",
    "    # Accuracy\n",
    "    val_acc = (val_preds == y_val).float().mean().item()\n",
    "    \n",
    "    print(f\"‚úì Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nüìã Per-Intent Performance:\")\n",
    "    for intent_id in range(num_classes):\n",
    "        intent_name = intent_map[intent_id]\n",
    "        mask = y_val == intent_id\n",
    "        if mask.sum() > 0:\n",
    "            intent_acc = (val_preds[mask] == y_val[mask]).float().mean().item()\n",
    "            count = mask.sum().item()\n",
    "            print(f\"   {intent_name:30s}: {intent_acc:.3f} ({count:2d} samples)\")\n",
    "\n",
    "# Test on ALL training data (should be near perfect)\n",
    "with torch.no_grad():\n",
    "    all_outputs = cnn_model(sentence_embeddings.to(device))\n",
    "    all_preds = all_outputs.argmax(1)\n",
    "    all_labels = torch.tensor(df['label'].values, dtype=torch.long).to(device)\n",
    "    \n",
    "    train_acc = (all_preds == all_labels).float().mean().item()\n",
    "    print(f\"Accuracy on FULL training set: {train_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ NOTEBOOK COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nYour model is ready to use!\")\n",
    "\n",
    "# ============================================================================\n",
    "# FRESH START - DELETE EVERYTHING AND RETRAIN\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. Delete saved model\n",
    "if os.path.exists(\"cnn_chattea.pth\"):\n",
    "    os.remove(\"cnn_chattea.pth\")\n",
    "    print(\"‚úì Deleted old model\")\n",
    "\n",
    "# 2. Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "# 3. Restart notebook kernel (Kernel ‚Üí Restart & Run All)\n",
    "print(\"\\n‚ö†Ô∏è  NOW RESTART KERNEL AND RUN ALL CELLS FROM TOP!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
